# Sprint 33: Enhanced Directory Indexing & Live Progress Visualization

**Sprint Duration:** TBD
**Branch:** `sprint-33-directory-indexing`
**Status:** PLANNED

---

## Objective

Verbesserung der Admin-Indizierung mit Verzeichnisauswahl, Dateivorschau, detaillierter Echtzeit-Fortschrittsanzeige, paralleler Verarbeitung und persistentem Logging.

---

## Features Overview

| # | Feature | Story Points | Priority |
|---|---------|--------------|----------|
| 33.1 | Verzeichnisauswahl-Dialog | 5 SP | P0 |
| 33.2 | Dateilisten mit Farbkodierung | 5 SP | P0 |
| 33.3 | Live-Fortschrittsanzeige (Kompakt) | 5 SP | P0 |
| 33.4 | Detail-Dialog (Seite, VLM, Chunks, Pipeline, Entities) | 13 SP | P1 |
| 33.5 | Error-Tracking mit Button | 5 SP | P1 |
| 33.6 | Live-Log Stream | 8 SP | P2 |
| 33.7 | Persistente Logging-Datenbank + API | 13 SP | P1 |
| 33.8 | Parallele Dateiverarbeitung | 8 SP | P1 |
| 33.9 | DoclingParsedDocument Interface Fix (TD-044) | 5 SP | P0 |
| 33.10 | Multi-Format Section Extraction & Legacy Handling | 5 SP | P0 |
| 33.11 | VLM Pipeline Integration & Image Filtering | 5 SP | P1 |
| **Gesamt** | | **77 SP** | |

---

## Feature 33.1: Verzeichnisauswahl-Dialog (5 SP)

### Beschreibung
Auswahldialog f√ºr lokale Verzeichnisse mit Option f√ºr rekursive Suche.

### Anforderungen
- [ ] Pfad-Eingabefeld f√ºr Verzeichnispfad
- [ ] Browse-Button zum √ñffnen eines Verzeichnis-Dialogs
- [ ] Checkbox: "Rekursiv durchsuchen" (Unterverzeichnisse einbeziehen)
- [ ] Validierung: Pr√ºfen ob Pfad existiert und lesbar ist
- [ ] Backend-Endpoint: `POST /api/v1/admin/indexing/scan-directory`

### Technische Details
```typescript
// Frontend: DirectorySelector.tsx
interface DirectorySelectorProps {
  onDirectorySelected: (path: string, recursive: boolean) => void;
}

// Backend Request
interface ScanDirectoryRequest {
  path: string;
  recursive: boolean;
}

// Backend Response
interface ScanDirectoryResponse {
  path: string;
  recursive: boolean;
  files: FileInfo[];
  statistics: {
    total: number;
    docling_supported: number;
    llamaindex_supported: number;
    unsupported: number;
  };
}
```

### Acceptance Criteria
- [ ] Verzeichnispfad kann eingegeben werden
- [ ] Rekursiv-Option funktioniert
- [ ] Ung√ºltige Pfade werden mit Fehlermeldung abgelehnt

---

## Feature 33.2: Dateilisten mit Farbkodierung (5 SP)

### Beschreibung
Nach Verzeichnisauswahl: Anzeige aller gefundenen Dateien mit Farbkodierung nach Unterst√ºtzungsstatus.

### Farbschema
| Farbe | CSS-Klasse | Bedeutung | Dateitypen |
|-------|------------|-----------|------------|
| Dunkelgr√ºn | `bg-green-700` | Docling (GPU-OCR, optimal) | PDF, DOCX, PPTX, XLSX, PNG, JPG |
| Hellgr√ºn | `bg-green-400` | LlamaIndex Fallback | TXT, MD, HTML, JSON, CSV, RTF |
| Rot | `bg-red-500` | Nicht unterst√ºtzt | EXE, ZIP, MP4, etc. |

### UI-Mockup
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìÅ /data/documents (rekursiv)                           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ Statistik:                                              ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ 23 Dateien gefunden                                 ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ 15 √ó Docling-unterst√ºtzt (PDF, DOCX)      [‚ñà‚ñà‚ñà‚ñà‚ñà]  ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ 6 √ó LlamaIndex-unterst√ºtzt (TXT, MD)      [‚ñà‚ñà‚ñë‚ñë‚ñë]  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ 2 √ó Nicht unterst√ºtzt (wird √ºbersprungen) [‚ñà‚ñë‚ñë‚ñë‚ñë]  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ Dateien:                                                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ üü¢ financial_report_2024.pdf        2.4 MB  Docling ‚îÇ ‚îÇ
‚îÇ ‚îÇ üü¢ presentation_q3.pptx             1.8 MB  Docling ‚îÇ ‚îÇ
‚îÇ ‚îÇ üü° readme.md                        12 KB   LlamaIx ‚îÇ ‚îÇ
‚îÇ ‚îÇ üî¥ archive.zip                      45 MB   Skip    ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ [Alle ausw√§hlen] [Keine ausw√§hlen] [Nur unterst√ºtzte]   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ [Indizierung starten]                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Technische Details
```typescript
// Datei-Typ-Mapping
const FILE_TYPE_CONFIG = {
  docling: {
    extensions: ['.pdf', '.docx', '.pptx', '.xlsx', '.png', '.jpg', '.jpeg'],
    color: 'bg-green-700',
    label: 'Docling'
  },
  llamaindex: {
    extensions: ['.txt', '.md', '.html', '.json', '.csv', '.rtf'],
    color: 'bg-green-400',
    label: 'LlamaIndex'
  },
  unsupported: {
    color: 'bg-red-500',
    label: 'Nicht unterst√ºtzt'
  }
};
```

### Acceptance Criteria
- [ ] Dateien werden farbkodiert angezeigt
- [ ] Statistik zeigt Anzahl pro Kategorie
- [ ] Dateien k√∂nnen einzeln ausgew√§hlt/abgew√§hlt werden

---

## Feature 33.3: Live-Fortschrittsanzeige Kompakt (5 SP)

### Beschreibung
Kompakte Fortschrittsanzeige w√§hrend der Indizierung mit aktuellem Dateinamen, Seitenzahl und Gesamtfortschritt.

### UI-Mockup
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üìÑ Verarbeite: financial_report_2024.pdf              ‚îÇ
‚îÇ  üìë Seite: 12 / 45                                      ‚îÇ
‚îÇ  üìÅ Datei: 3 / 23                                       ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 27%                               ‚îÇ
‚îÇ  Gesch√§tzte Restzeit: ~4 min 32s                        ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  [Details...] [Errors (0)] [Log] [Abbrechen]            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### SSE-Events vom Backend
```typescript
interface IngestionProgressEvent {
  type: 'progress';
  job_id: string;
  current_file: string;
  current_page: number;
  total_pages: number;
  files_processed: number;
  files_total: number;
  percentage: number;
  estimated_remaining_seconds: number;
}
```

### Acceptance Criteria
- [ ] Aktueller Dateiname wird angezeigt
- [ ] Seitennummer wird live aktualisiert
- [ ] Fortschrittsbalken zeigt Gesamtfortschritt
- [ ] Gesch√§tzte Restzeit wird berechnet

---

## Feature 33.4: Detail-Dialog (13 SP)

### Beschreibung
Erweitertes Panel mit detaillierten Informationen zum aktuellen Indizierungsfortschritt.

### Bereiche

#### Bereich 1: Dokument & Seitenvorschau
- Thumbnail der aktuellen Seite (PNG aus Docling)
- Erkannte Elemente (Tabellen, Bilder, Wortanzahl)
- Parser-Info (Docling/LlamaIndex)

#### Bereich 2: VLM-Bildanalyse
- Liste aller Bilder auf der aktuellen Seite
- Thumbnail + VLM-Status f√ºr jedes Bild
- Generierte Beschreibung anzeigen
- VLM-Kosten und Statistik

#### Bereich 3: Chunk-Verarbeitung
- Aktueller Chunk-Text (Preview)
- Token-Anzahl und Section-Name
- Navigation zwischen Chunks
- VLM-Annotation-Hinweis wenn Bild enthalten

#### Bereich 4: Pipeline-Status
- Status aller Pipeline-Phasen:
  - Parsing (Docling)
  - VLM-Analyse
  - Chunking
  - Embeddings
  - BM25 Index
  - Graph (Neo4j)
- Aktuelle Operation mit Fortschritt

#### Bereich 5: Extrahierte Entit√§ten (Live)
- Neue Entit√§ten aus aktueller Seite
- Neue Relationen
- Gesamtz√§hler

### Acceptance Criteria
- [ ] Seitenvorschau wird als Thumbnail angezeigt
- [ ] VLM-Beschreibungen werden live angezeigt
- [ ] Chunks k√∂nnen durchgebl√§ttert werden
- [ ] Pipeline-Status zeigt alle Phasen
- [ ] Entit√§ten werden live aktualisiert

---

## Feature 33.5: Error-Tracking mit Button (5 SP)

### Beschreibung
Error-Button in der Hauptansicht mit Anzahl der Fehler. Bei Klick √∂ffnet sich ein Dialog mit allen Fehlern.

### Fehler-Kategorien
| Typ | Symbol | Farbe | Bedeutung |
|-----|--------|-------|-----------|
| ERROR | ‚ùå | Rot | Datei √ºbersprungen |
| WARNING | ‚ö†Ô∏è | Orange | Problem, aber fortgesetzt |
| INFO | ‚ÑπÔ∏è | Blau | Hinweis (z.B. Fallback) |

### UI-Mockup Error-Dialog
```
‚îå‚îÄ Fehler w√§hrend Indizierung (3) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ Fehler 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è WARNUNG | 14:23:45                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ üìÑ report_2023.pdf, Seite 7                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ VLM-Timeout: Bildanalyse nach 30s abgebrochen      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Üí Fallback: Bild ohne Beschreibung indiziert       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  [Als CSV exportieren] [Schlie√üen]                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Acceptance Criteria
- [ ] Error-Button zeigt Anzahl der Fehler
- [ ] Button ist rot wenn Fehler > 0, grau wenn 0
- [ ] Dialog zeigt alle Fehler mit Details
- [ ] CSV-Export funktioniert

---

## Feature 33.6: Live-Log Stream (8 SP)

### Beschreibung
Scrollbarer Log-Bereich mit allen Ereignissen der Indizierung.

### UI-Mockup
```
‚îå‚îÄ Indizierungs-Log ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  [Auto-Scroll ‚úì] [Filter: Alle ‚ñº] [Suche: ________]    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
‚îÇ  14:23:41 [INFO]  Starte Verzeichnis-Scan...           ‚îÇ
‚îÇ  14:23:42 [INFO]  üìÑ report_2023.pdf - Parsing...      ‚îÇ
‚îÇ  14:23:45 [DEBUG] VLM Response: 892 tokens, 2.1s       ‚îÇ
‚îÇ  14:23:53 [WARN]  VLM Timeout auf Seite 7              ‚îÇ
‚îÇ  ...                                                    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
‚îÇ  [Export Log] [Schlie√üen]                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Filter-Optionen
- Level: Alle / INFO / DEBUG / WARN / ERROR
- Nach Datei filtern
- Nach Pipeline-Phase filtern

### Acceptance Criteria
- [ ] Logs werden live gestreamt
- [ ] Auto-Scroll funktioniert
- [ ] Filter funktionieren
- [ ] Log-Export als TXT/JSON

---

## Feature 33.7: Persistente Logging-Datenbank (13 SP)

### Beschreibung
SQLite-Datenbank f√ºr persistentes Tracking aller Indizierungsjobs mit API-Endpoints.

### Datenbank-Schema
```sql
CREATE TABLE ingestion_jobs (
    id TEXT PRIMARY KEY,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    status TEXT NOT NULL,  -- running, completed, failed, cancelled
    directory_path TEXT NOT NULL,
    recursive BOOLEAN NOT NULL,
    total_files INTEGER NOT NULL,
    processed_files INTEGER DEFAULT 0,
    total_errors INTEGER DEFAULT 0,
    total_warnings INTEGER DEFAULT 0,
    config JSON  -- Speichert Konfiguration zum Zeitpunkt des Jobs
);

CREATE TABLE ingestion_events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id TEXT NOT NULL REFERENCES ingestion_jobs(id),
    timestamp TIMESTAMP NOT NULL,
    level TEXT NOT NULL,  -- INFO, DEBUG, WARN, ERROR
    phase TEXT,  -- parsing, vlm, chunking, embedding, bm25, graph
    file_name TEXT,
    page_number INTEGER,
    chunk_id TEXT,
    message TEXT NOT NULL,
    details JSON
);

CREATE TABLE ingestion_files (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id TEXT NOT NULL REFERENCES ingestion_jobs(id),
    file_path TEXT NOT NULL,
    file_name TEXT NOT NULL,
    file_type TEXT NOT NULL,
    file_size_bytes INTEGER,
    parser_used TEXT,  -- docling, llamaindex
    status TEXT NOT NULL,  -- pending, processing, completed, failed, skipped
    pages_total INTEGER,
    pages_processed INTEGER DEFAULT 0,
    chunks_created INTEGER DEFAULT 0,
    entities_extracted INTEGER DEFAULT 0,
    relations_extracted INTEGER DEFAULT 0,
    vlm_images_total INTEGER DEFAULT 0,
    vlm_images_processed INTEGER DEFAULT 0,
    processing_time_ms INTEGER,
    error_message TEXT,
    started_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- Index f√ºr Performance
CREATE INDEX idx_events_job_id ON ingestion_events(job_id);
CREATE INDEX idx_events_level ON ingestion_events(level);
CREATE INDEX idx_files_job_id ON ingestion_files(job_id);
CREATE INDEX idx_jobs_status ON ingestion_jobs(status);
```

### API-Endpoints
```
GET  /api/v1/admin/ingestion/jobs                    -- Liste aller Jobs
GET  /api/v1/admin/ingestion/jobs/{id}               -- Job-Details
GET  /api/v1/admin/ingestion/jobs/{id}/events        -- Events f√ºr Job
GET  /api/v1/admin/ingestion/jobs/{id}/files         -- Dateien f√ºr Job
GET  /api/v1/admin/ingestion/jobs/{id}/errors        -- Nur Fehler
POST /api/v1/admin/ingestion/jobs/{id}/cancel        -- Job abbrechen
DELETE /api/v1/admin/ingestion/jobs/{id}             -- Job l√∂schen
```

### Konfiguration
```yaml
# config/settings.yaml
ingestion:
  logging:
    retention_days: 30          # Wie lange Logs aufbewahrt werden
    max_jobs: 1000              # Maximale Anzahl gespeicherter Jobs
    cleanup_on_startup: true    # Alte Jobs beim Start bereinigen
```

### Acceptance Criteria
- [ ] SQLite-Datenbank wird erstellt
- [ ] Jobs werden persistiert
- [ ] Events werden geloggt
- [ ] API-Endpoints funktionieren
- [ ] Retention/Cleanup funktioniert per Konfiguration

---

## Feature 33.8: Parallele Dateiverarbeitung (8 SP)

### Beschreibung
Mehrere Dateien k√∂nnen parallel verarbeitet werden, um die Gesamtzeit zu reduzieren.

### Technische Details
```python
# Konfiguration
PARALLEL_FILES = 3  # Anzahl parallel verarbeiteter Dateien
PARALLEL_CHUNKS = 10  # Anzahl parallel verarbeiteter Chunks f√ºr Embeddings

# Implementierung mit asyncio
async def process_files_parallel(files: list[Path], max_workers: int = 3):
    semaphore = asyncio.Semaphore(max_workers)

    async def process_with_semaphore(file: Path):
        async with semaphore:
            return await process_single_file(file)

    tasks = [process_with_semaphore(f) for f in files]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results
```

### Konfiguration
```yaml
# config/settings.yaml
ingestion:
  parallelization:
    max_parallel_files: 3       # Parallele Dateien
    max_parallel_chunks: 10     # Parallele Chunk-Embeddings
    max_parallel_vlm: 2         # Parallele VLM-Requests (API-Limit beachten)
```

### UI-Anpassung
- Fortschrittsanzeige zeigt mehrere aktive Dateien
- Detail-Dialog kann zwischen Dateien wechseln

### Acceptance Criteria
- [ ] Mehrere Dateien werden parallel verarbeitet
- [ ] Parallelit√§t ist konfigurierbar
- [ ] Fortschrittsanzeige zeigt alle aktiven Dateien
- [ ] Fehler in einer Datei stoppen nicht die anderen

---

## Feature 33.9: DoclingParsedDocument Interface Fix (TD-044) (5 SP)

### Beschreibung
Kritische Fehlerbehebung f√ºr DoclingParsedDocument Interface-Mismatch, der Section Extraction f√ºr alle Dokumentformate blockiert hat.

### Problem
- `DoclingParsedDocument` (HTTP API Wrapper) fehlten `.body` und `.document` Attribute
- Section Extraction scheiterte f√ºr ALLE Formate (PDF, DOCX, PPTX - nicht nur PowerPoint)
- Dead Code in `langgraph_nodes.py` (Zeilen 510-529) wurde nie ausgef√ºhrt
- Doppeltes Chunking: Pipeline ‚Üí 1 Chunk, LightRAG ‚Üí 122 Chunks
- Symptom: Alle Dateien bekamen nur 1 Chunk ohne Sections

### Root Cause
```python
# DoclingParsedDocument (HTTP wrapper) war:
class DoclingParsedDocument:
    json_content: dict  # Parsed document as dict
    # FEHLEND: .body und .document wie native Docling Objekte

# Aber section_extraction.py erwartete:
if isinstance(parsed_doc.document.body, list):  # AttributeError!
```

### L√∂sung

#### 1. Property Accessors zu DoclingParsedDocument hinzuf√ºgen
```python
@property
def body(self):
    """Access document body from Docling JSON."""
    return self.json_content.get("body")

@property
def document(self):
    """Self-reference for native Docling object interface."""
    return self
```

#### 2. Dead Code aus langgraph_nodes.py entfernen (Zeilen 510-529)
```python
# ENTFERNEN: Dieser Code wurde nie ausgef√ºhrt
if hasattr(parsed_docling_doc, "document") and parsed_docling_doc.document is not None:
    # This branch never executed for DoclingParsedDocument
    sections = extract_sections_from_docling(parsed_docling_doc.document.body)
else:
    # Always took this path, so dead code above was useless
    sections = extract_sections_from_docling(parsed_docling_doc.json_content.get("body"))
```

#### 3. section_extraction.py f√ºr Dict-Format aktualisieren
```python
# Jetzt funktioniert mit beiden Formaten:
# - Docling native Objekte: parsed_doc.document.body
# - DoclingParsedDocument HTTP wrapper: parsed_doc.body (via property)
def extract_sections(body_content):
    if isinstance(body_content, dict):
        # Handle dict format from Docling JSON
        return extract_from_dict(body_content)
    elif isinstance(body_content, list):
        # Handle native Docling object format
        return extract_from_list(body_content)
```

### Auswirkungen
- Section Extraction funktioniert jetzt f√ºr PDF, DOCX, PPTX
- Kein doppeltes Chunking mehr
- Dead Code entfernt, Codebase sauberer
- Backward compatible (alle Dateitypen)

### Betroffene Dateien
- `src/components/ingestion/docling_client.py` (Add properties)
- `src/components/ingestion/langgraph_nodes.py` (Remove dead code)
- `src/components/ingestion/section_extraction.py` (Handle dict format)

### Acceptance Criteria
- [ ] Section Extraction funktioniert f√ºr PDF
- [ ] Section Extraction funktioniert f√ºr DOCX
- [ ] Section Extraction funktioniert f√ºr PPTX
- [ ] Kein doppeltes Chunking mehr
- [ ] Dead Code entfernt
- [ ] Alle Tests bestehen (>80% coverage)
- [ ] Integration Tests f√ºr all 3 Formate

### Test-Strategie
```python
@pytest.mark.parametrize("file_format", ["pdf", "docx", "pptx"])
async def test_section_extraction_for_all_formats(file_format):
    # Test mit echten Test-Dateien f√ºr alle Formate
    parsed_doc = await docling_client.parse_document(test_file[file_format])
    sections = extract_sections(parsed_doc)
    assert len(sections) > 0
    assert all(s.heading for s in sections)
```

### Dokumentation
- **TD-044:** `docs/technical-debt/TD-044_DOCLING_PARSED_DOCUMENT_INTERFACE.md`
- **Sprint 33:** Diese Feature dokumentiert in SPRINT_33_PLAN.md
- **Architecture:** ARCHITECTURE_EVOLUTION.md aktualisiert

### Abh√§ngigkeiten
- Keine - Standalone Bug Fix
- Blockiert: Alle anderen Sprint-33-Features (bis TD-044 behoben)

---

## Feature 33.10: Multi-Format Section Extraction & Legacy Format Handling (5 SP)

### Beschreibung
Verbesserungen an der Section Extraction f√ºr verschiedene Dokumentformate nach detaillierter API-Analyse und Tests.

### Erkenntnisse aus der Docling API-Analyse

#### Docling DocItemLabel Enum
Docling verwendet verschiedene Labels je nach Dokumenttyp:
- **PPTX:** `title`, `subtitle-level-1`, `subtitle-level-2`, `paragraph`, `list_item`
- **DOCX:** `section_header` (f√ºr Word Heading Styles), `paragraph`, `list_item`
- **PDF:** `section_header`, `title`, `paragraph`

**Wichtig:** Unser Code hatte urspr√ºnglich nur `title` Labels gepr√ºft, aber DOCX verwendet `section_header` mit `level` Attribut!

#### Format Support Matrix

| Format | Status | Strategy | Labels | Notes |
|--------|--------|----------|--------|-------|
| **PPTX** | Working | `labels` | `title`, `subtitle-level-*` | Slide titles werden erkannt |
| **DOCX** (mit Word Heading Styles) | Fixed | `labels` | `section_header` mit `level` | Nach Fix f√ºr `section_header` Label |
| **DOCX** (ohne Heading Styles) | Fixed | `formatting` | `paragraph` mit `formatting.bold` | Fallback f√ºr formatierte Headings |
| **PDF** | Working | `labels` | `title`, `section_header` | Standard PDF Headings |
| **PPT** | NOT SUPPORTED | N/A | N/A | Legacy Binary Format |
| **DOC** | NOT SUPPORTED | N/A | N/A | Legacy Binary Format |
| **XLS** | NOT SUPPORTED | N/A | N/A | Legacy Binary Format |

### Implementierte Fixes

#### 1. `section_header` Label Support
```python
# Vorher: Nur title Labels
HEADING_LABELS = {"title", "subtitle-level-1", "subtitle-level-2"}

# Nachher: Auch section_header
HEADING_LABELS = {"title", "section_header", "subtitle-level-1", "subtitle-level-2"}
```

#### 2. Level-Attribut f√ºr section_header
```python
def _get_heading_level(heading_type: str, text_item: dict | None = None) -> int:
    # section_header hat level-Attribut (1, 2, 3, etc.)
    if heading_type == "section_header" and text_item:
        level = text_item.get("level")
        if level and isinstance(level, int) and 1 <= level <= 6:
            return level
        return 1
    # Andere Labels: Mapping
    heading_map = {"title": 1, "section_header": 1, "subtitle-level-1": 2, "subtitle-level-2": 3}
    return heading_map.get(heading_type, 1)
```

#### 3. Legacy Format Rejection
```python
# docling_client.py: Runtime check f√ºr unsupported formats
LEGACY_FORMATS = {".doc", ".xls", ".ppt"}
if file_ext in LEGACY_FORMATS:
    raise IngestionError(
        f"Legacy Office format '{file_ext}' is NOT SUPPORTED. "
        f"Please convert to modern format (.docx, .xlsx, .pptx) before processing."
    )
```

### Betroffene Dateien
- `src/components/ingestion/section_extraction.py`
  - Added `section_header` to HEADING_LABELS
  - Updated `_get_heading_level()` for level attribute
  - Strategy detection f√ºr `labels` vs `formatting`
- `src/components/ingestion/docling_client.py`
  - Added format support matrix documentation
  - Added legacy format runtime rejection

### Test-Ergebnisse

**OT_requirements_FNT_Command_20221219.docx** (mit Word Heading Styles):
```
section_header labels: 42
Level distribution:
- L1: 8 headings (Hauptkapitel)
- L2: 22 headings (Unterkapitel)
- L3: 12 headings (Abschnitte)
```

**DE-D-AdvancedAdministration_0368.docx** (ohne Word Heading Styles):
```
section_header labels: 0 (uses formatting.bold fallback)
Formatting-based headings: 187
Strategy: formatting
```

### Acceptance Criteria
- [x] `section_header` Label wird erkannt
- [x] Level-Attribut wird korrekt verarbeitet (1-6)
- [x] DOCX mit Word Heading Styles extrahiert Sections korrekt
- [x] DOCX ohne Heading Styles nutzt Formatting-Fallback
- [x] Legacy Formate (.doc, .xls, .ppt) werden mit klarer Fehlermeldung abgelehnt
- [x] API-Dokumentation im Code aktualisiert
- [x] TD-044 Addendum dokumentiert

### Lessons Learned
- Docling API Dokumentation ist nicht vollst√§ndig - praktisches Testen essentiell
- DOCX verwendet `section_header` statt `title` f√ºr Word Heading Styles
- Legacy Office Formate (Binary) werden von Docling nicht unterst√ºtzt (python-docx limitation)
- Formatting-based heading detection ist guter Fallback f√ºr DOCX ohne Styles

---

## Feature 33.11: VLM Pipeline Integration & Image Filtering (5 SP)

### Beschreibung
Integration des VLM Image Enrichment Nodes in die LangGraph Ingestion Pipeline mit optimierten Bildfiltern zur Kosteneinsparung.

### Problem
- `image_enrichment_node` existierte bereits (Feature 21.6), war aber NICHT in die Pipeline eingebunden
- Keine Bildfilterung f√ºr irrelevante Bilder (kleine Icons, Platzhalter, Banner)
- Pipeline hatte nur 5 Nodes: `memory_check ‚Üí parse ‚Üí chunking ‚Üí embedding ‚Üí graph`

### L√∂sung

#### 1. VLM Node in Pipeline integriert
```python
# langgraph_pipeline.py - Neue 6-Node Pipeline
graph.add_edge("memory_check", "parse")
graph.add_edge("parse", "image_enrichment")  # NEU: VLM nach Parsing
graph.add_edge("image_enrichment", "chunking")
graph.add_edge("chunking", "embedding")
graph.add_edge("embedding", "graph")
```

#### 2. Optimierte Bildfilter (Kostenersparnis)
```python
# image_processor.py - Verbesserte Defaults
class ImageProcessorConfig:
    min_size: int = 200           # War 100 - Skip kleine Icons
    min_aspect_ratio: float = 0.2 # War 0.1 - Skip schmale Balken
    max_aspect_ratio: float = 5.0 # War 10.0 - Skip breite Banner
    min_unique_colors: int = 16   # NEU - Skip einfarbige Platzhalter
```

#### 3. Farbfilter f√ºr Platzhalter-Bilder
```python
def count_unique_colors(image: Image.Image, sample_size: int = 10000) -> int:
    """Z√§hlt einzigartige Farben (mit Sampling f√ºr Performance)."""
    pixels = list(image.getdata())
    if len(pixels) > sample_size:
        pixels = random.sample(pixels, sample_size)
    return len(set(pixels))

def should_process_image(..., min_unique_colors: int = 16) -> tuple[bool, str]:
    # ... size und aspect ratio checks ...
    if min_unique_colors > 0:
        unique_colors = count_unique_colors(image)
        if unique_colors < min_unique_colors:
            return False, f"too_few_colors: {unique_colors} < {min_unique_colors}"
    return True, "valid"
```

### Pipeline Flow (Neu)
```
START
  ‚Üì
memory_check_node (5% progress)
  ‚Üì
parse_node (20% progress) - Docling oder LlamaIndex
  ‚Üì
image_enrichment_node (35% progress) - NEU: Qwen3-VL Beschreibungen
  ‚Üì
chunking_node (50% progress)
  ‚Üì
embedding_node (75% progress)
  ‚Üì
graph_extraction_node (100% progress)
  ‚Üì
END
```

### VLM-Text Platzierung
- VLM-Beschreibungen werden in `picture_item.text` eingef√ºgt (Docling-Objekt)
- Beim Chunking flie√üt der VLM-Text in den richtigen Dokumentkontext
- BBox-Metadaten bleiben f√ºr pr√§zise Lokalisierung erhalten
- Funktioniert f√ºr alle Docling-unterst√ºtzten Formate (PDF, DOCX, PPTX, XLSX)

### Betroffene Dateien
- `src/components/ingestion/image_processor.py`
  - Neue Defaults f√ºr Filter (min_size=200, aspect ratios, colors)
  - `count_unique_colors()` Funktion hinzugef√ºgt
  - `should_process_image()` erweitert um Farbfilter
- `src/components/ingestion/langgraph_pipeline.py`
  - Import von `image_enrichment_node`
  - Node zur Pipeline hinzugef√ºgt zwischen `parse` und `chunking`
  - Timing-Logs aktualisiert f√ºr VLM-Metrik

### Test-Ergebnisse
```
IMAGE FILTER TESTS - Sprint 33
============================================================

1. Single color image:    1 unique colors -> too_few_colors: 1 < 16    PASS
2. Small image (50x50):   -> too_small: 50x50 < 200px                  PASS
3. Wide image (10:1):     -> too_small: 1000x100 < 200px               PASS
4. Narrow image (0.1:1):  -> too_small: 100x1000 < 200px               PASS
5. Good gradient image:   9609 unique colors -> valid                  PASS

ALL FILTER TESTS PASSED!
```

### Erwartete Kosteneinsparung
| Filter | Gesch√§tzte Filterrate | Einsparung |
|--------|----------------------|------------|
| min_size: 200px | ~30% Icons/Logos | 30% VLM Calls |
| aspect_ratio: 0.2-5.0 | ~10% Banner/Bars | 10% VLM Calls |
| min_unique_colors: 16 | ~20% Platzhalter | 20% VLM Calls |
| **Gesamt** | | **~50% weniger VLM Calls** |

### Acceptance Criteria
- [x] `image_enrichment_node` ist in Pipeline eingebunden
- [x] Filter-Defaults optimiert (min_size=200, aspect ratios)
- [x] Farbfilter f√ºr einfarbige Bilder implementiert
- [x] Alle Filter-Tests bestehen
- [x] Pipeline-Timing enth√§lt VLM-Metrik
- [x] Dokumentation aktualisiert

---

## Abh√§ngigkeiten

### Bestehende Komponenten (wiederverwendet)
- `DoclingContainerClient` - Dokument-Parsing
- `ImageProcessor` - VLM-Bildanalyse
- `ChunkingService` - Adaptive Chunking
- `QdrantClientWrapper` - Embeddings & BM25
- `LightRAGClient` - Graph-Extraktion
- SSE-Streaming (bereits f√ºr Chat implementiert)

### Neue Komponenten
- `IngestionJobTracker` - SQLite-basiertes Job-Tracking
- `DirectoryScanner` - Verzeichnis-Scanning mit Typ-Erkennung
- `ParallelIngestionOrchestrator` - Parallele Verarbeitung

---

## Nicht im Scope

- ‚ùå Job-Wiederaufnahme nach Abbruch
- ‚ùå Push-Notifications bei Job-Abschluss
- ‚ùå Cloud-Storage-Integration (S3, Azure Blob)
- ‚ùå Scheduling/Cron-Jobs

---

## Risiken

| Risiko | Wahrscheinlichkeit | Impact | Mitigation |
|--------|-------------------|--------|------------|
| Docling Container nicht verf√ºgbar | Mittel | Hoch | LlamaIndex Fallback |
| VLM API Rate-Limiting | Mittel | Mittel | Konfigurierbare Parallelit√§t |
| SQLite Lock-Contention bei Parallelisierung | Niedrig | Mittel | WAL-Mode aktivieren |
| Memory bei gro√üen Verzeichnissen | Niedrig | Mittel | Streaming/Batching |

---

## Definition of Done

- [ ] Alle Features implementiert und getestet
- [ ] Unit Tests f√ºr Backend-Komponenten (>80% Coverage)
- [ ] E2E Tests f√ºr Frontend-Flows
- [ ] API-Dokumentation aktualisiert
- [ ] CLAUDE.md aktualisiert
- [ ] Code-Review abgeschlossen
- [ ] Keine kritischen Bugs offen
