# COMPONENT INTERACTION MAP
**Project:** AEGIS RAG (Agentic Enterprise Graph Intelligence System)
**Purpose:** Complete data flow documentation - how components communicate
**Last Updated:** 2025-12-08 (Sprint 37 - Streaming Pipeline Architecture)

---

## ðŸ“‹ TABLE OF CONTENTS

1. [System Overview](#system-overview)
2. [Request Flow Scenarios](#request-flow-scenarios)
3. [Component Details](#component-details)
4. [API Contracts](#api-contracts)
5. [Data Flow Diagrams](#data-flow-diagrams)

---

## ðŸŽ¯ SYSTEM OVERVIEW

### High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AEGIS RAG System                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   React Frontend (Port 5173)                        â”‚          â”‚
â”‚  â”‚   (Sprint 15 SSE, Sprint 28 Perplexity UX)          â”‚          â”‚
â”‚  â”‚   Components:                                        â”‚          â”‚
â”‚  â”‚   - SearchResultsPage (SSE streaming)               â”‚          â”‚
â”‚  â”‚   - StreamingAnswer (custom ReactMarkdown)          â”‚          â”‚
â”‚  â”‚   - Citation (inline [1][2][3] with tooltips)       â”‚          â”‚
â”‚  â”‚   - FollowUpQuestions (grid layout, responsive)     â”‚          â”‚
â”‚  â”‚   - Settings (tabbed UI, localStorage)              â”‚          â”‚
â”‚  â”‚   - SettingsContext (React Context API)             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                 â”‚ HTTP POST /api/v1/chat (SSE)                     â”‚
â”‚                 â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              FastAPI Backend (Port 8000)                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚ Health API â”‚  â”‚ Retrieval APIâ”‚  â”‚ Graph Viz APIâ”‚         â”‚  â”‚
â”‚  â”‚  â”‚ (Sprint 2) â”‚  â”‚  (Sprint 2)  â”‚  â”‚ (Sprint 12)  â”‚         â”‚  â”‚
â”‚  â”‚  â”‚            â”‚  â”‚              â”‚  â”‚ Frontend:    â”‚         â”‚  â”‚
â”‚  â”‚  â”‚            â”‚  â”‚              â”‚  â”‚ Sprint 29 ðŸš§ â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                         â”‚
â”‚                            â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          LangGraph Multi-Agent Orchestration                  â”‚  â”‚
â”‚  â”‚                     (Sprint 4-9)                              â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚  â”‚ Router  â”‚â†’ â”‚ Vector  â”‚  â”‚  Graph  â”‚  â”‚ Memory  â”‚         â”‚  â”‚
â”‚  â”‚  â”‚  Agent  â”‚  â”‚  Agent  â”‚  â”‚  Agent  â”‚  â”‚  Agent  â”‚         â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚  â”‚                    â”‚            â”‚            â”‚               â”‚  â”‚
â”‚  â”‚               â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚               â”‚     Aggregator Node              â”‚          â”‚  â”‚
â”‚  â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                 â”‚                                  â”‚
â”‚                                 â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Storage Layer                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚  â”‚  Redis  â”‚  â”‚ Qdrant  â”‚  â”‚ Neo4j   â”‚  â”‚AegisLLMProxyâ”‚     â”‚  â”‚
â”‚  â”‚  â”‚(Memory) â”‚  â”‚(Vector) â”‚  â”‚ (Graph) â”‚  â”‚ Multi-Cloud â”‚     â”‚  â”‚
â”‚  â”‚  â”‚Port 6379â”‚  â”‚Port 6333â”‚  â”‚Port 7687â”‚  â”‚ LLM Routing â”‚     â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â”‚ BGE-M3  â”‚  â”‚         â”‚  â”‚ (ADR-033)   â”‚     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Communication Patterns

| Source | Target | Protocol | Data Format | Purpose |
|--------|--------|----------|-------------|---------|
| Gradio UI | FastAPI | HTTP/REST | JSON | User queries, document upload |
| FastAPI | LangGraph | Python Call | Pydantic | Agent orchestration |
| LangGraph | Redis | Redis Protocol | Pickled State | State persistence |
| Vector Agent | Qdrant | gRPC/HTTP | Protobuf/JSON | Vector search |
| Vector Agent | BM25 | Python Call | Python objects | Keyword search |
| Graph Agent | LightRAG | Python Call | Python objects | Entity extraction |
| Graph Agent | Neo4j | Bolt Protocol | Cypher queries | Graph traversal, RELATES_TO queries |
| Memory Agent | Redis | Redis Protocol | JSON | Short-term memory |
| Memory Agent | Qdrant | gRPC/HTTP | Protobuf/JSON | Semantic memory |
| Memory Agent | Graphiti | Python Call | Python objects | Episodic memory |
| RelationExtractor | AegisLLMProxy | Python Call | Pydantic | RELATES_TO extraction via Qwen3-32B (Sprint 34) |
| RelationExtractor | Neo4j | Bolt Protocol | Cypher queries | Store RELATES_TO relationships |
| GraphViewer | Neo4j API | HTTP/REST | JSON | Edge filtering, relationship queries |
| All Agents | AegisLLMProxy | Python Call | Pydantic | Multi-cloud LLM routing (Sprint 25) |
| AegisLLMProxy | Ollama/Cloud | HTTP | JSON | LLM inference (local â†’ Alibaba â†’ OpenAI) |
| StreamingPipelineOrchestrator | TypedQueue[ChunkQueueItem] | AsyncIO Queue | Pydantic | Inter-stage chunk communication (Sprint 37) |
| StreamingPipelineOrchestrator | TypedQueue[EmbeddedChunkItem] | AsyncIO Queue | Pydantic | Embedding stage output queue (Sprint 37) |
| Admin UI | FastAPI SSE Endpoint | SSE | JSON | Real-time pipeline progress updates (Sprint 37) |
| Worker Pool | StreamingPipelineOrchestrator | Python Call | Pydantic | Dynamic worker configuration (Sprint 37) |
| EntityDeduplicator | UnifiedEmbeddingService | Python Call | Pydantic | BGE-M3 entity embeddings (Sprint 49.9) |
| EntityDeduplicator | Neo4j | Bolt Protocol | Cypher queries | Merge duplicate entities (Sprint 49) |
| SemanticRelationDeduplicator | UnifiedEmbeddingService | Python Call | Pydantic | BGE-M3 relation type embeddings (Sprint 49.7) |
| SemanticRelationDeduplicator | Redis | Redis Protocol | JSON | Relation type synonym overrides (Sprint 49.8) |
| RelationNormalizer | Neo4j | Bolt Protocol | Cypher queries | Normalize relations, handle symmetry (Sprint 49.3) |
| IndexConsistencyValidator | Qdrant | gRPC/HTTP | Protobuf/JSON | Cross-reference validation (Sprint 49.6) |
| IndexConsistencyValidator | Neo4j | Bolt Protocol | Cypher queries | Entity/relation integrity check (Sprint 49.6) |
| Admin API | Ollama | HTTP | JSON | List available LLM models (Sprint 49.1) |
| Admin API | Neo4j | Bolt Protocol | Cypher queries | List relationship types dynamically (Sprint 49.2) |

---

## ðŸ”„ REQUEST FLOW SCENARIOS

### Scenario 1: Simple Vector Search Query

**User Query:** "What is RAG?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Simple Vector Search (Hybrid Mode)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. User Input                                                      â”‚
â”‚     â””â”€> Gradio UI: Chatbot.submit("What is RAG?")                 â”‚
â”‚                                                                     â”‚
â”‚  2. HTTP Request                                                    â”‚
â”‚     â””â”€> POST http://localhost:8000/api/v1/chat                    â”‚
â”‚         Body: {                                                     â”‚
â”‚           "query": "What is RAG?",                                 â”‚
â”‚           "session_id": "abc123",                                  â”‚
â”‚           "rag_mode": "hybrid"                                     â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  3. FastAPI Handler                                                 â”‚
â”‚     â””â”€> def chat_endpoint(request: ChatRequest)                   â”‚
â”‚         - Validate request (Pydantic)                              â”‚
â”‚         - Extract query, session_id, rag_mode                      â”‚
â”‚                                                                     â”‚
â”‚  4. LangGraph Invocation                                           â”‚
â”‚     â””â”€> graph = create_agent_graph()                              â”‚
â”‚         initial_state = {                                          â”‚
â”‚           "query": "What is RAG?",                                 â”‚
â”‚           "session_id": "abc123",                                  â”‚
â”‚           "rag_mode": "hybrid"                                     â”‚
â”‚         }                                                          â”‚
â”‚         result = await graph.ainvoke(initial_state)                â”‚
â”‚                                                                     â”‚
â”‚  5. Router Agent (Node: route_query)                               â”‚
â”‚     â””â”€> Classify query type                                       â”‚
â”‚         - Input: "What is RAG?"                                    â”‚
â”‚         - LLM Call: AegisLLMProxy (Sprint 25 Feature 25.10)       â”‚
â”‚           proxy = get_aegis_llm_proxy()                            â”‚
â”‚           response = await proxy.complete(                         â”‚
â”‚             prompt="Classify: What is RAG?",                       â”‚
â”‚             quality=QualityRequirement.LOW,  # Router task         â”‚
â”‚             task_type=TaskType.QUERY_UNDERSTANDING                 â”‚
â”‚           )                                                        â”‚
â”‚           # Multi-cloud routing: Local Ollama â†’ Alibaba â†’ OpenAI  â”‚
â”‚         - Response: {"type": "SIMPLE", "intent": "definition"}     â”‚
â”‚         - Decision: Route to Vector Agent (rag_mode=hybrid)        â”‚
â”‚                                                                     â”‚
â”‚  6. Vector Agent (Node: vector_search)                             â”‚
â”‚     â””â”€> Parallel Execution: Vector + BM25                         â”‚
â”‚                                                                     â”‚
â”‚         A. Embedding Generation                                    â”‚
â”‚            â””â”€> UnifiedEmbeddingService.embed("What is RAG?")      â”‚
â”‚                - LRU Cache Check: MISS                             â”‚
â”‚                - Ollama Call: bge-m3 (Sprint 16)                   â”‚
â”‚                  POST http://localhost:11434/api/embeddings        â”‚
â”‚                  Body: {                                           â”‚
â”‚                    "model": "bge-m3",                              â”‚
â”‚                    "prompt": "What is RAG?"                        â”‚
â”‚                  }                                                 â”‚
â”‚                - Response: [0.123, -0.456, ..., 0.789] (1024d)     â”‚
â”‚                - Cache Store: LRU[hash("What is RAG?")] = vector   â”‚
â”‚                                                                     â”‚
â”‚         B. Vector Search (Qdrant)                                  â”‚
â”‚            â””â”€> QdrantClient.search(                               â”‚
â”‚                  collection="aegis-rag-documents",                 â”‚
â”‚                  query_vector=[0.123, -0.456, ..., 0.789],        â”‚
â”‚                  limit=10                                          â”‚
â”‚                )                                                   â”‚
â”‚                gRPC Call: localhost:6334 (or HTTP :6333)           â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "id": "doc1",                                   â”‚
â”‚                    "score": 0.92,                                  â”‚
â”‚                    "payload": {                                    â”‚
â”‚                      "text": "RAG is Retrieval-Augmented...",      â”‚
â”‚                      "source": "rag_overview.md"                   â”‚
â”‚                    }                                               â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                                                                     â”‚
â”‚         C. BM25 Search (Local)                                     â”‚
â”‚            â””â”€> BM25Search.search("What is RAG?", top_k=10)        â”‚
â”‚                - Load index: pickle.load("bm25_index.pkl")         â”‚
â”‚                - Tokenize query: ["what", "rag"]                   â”‚
â”‚                - Compute BM25 scores                               â”‚
â”‚                - Response: [                                       â”‚
â”‚                    {                                               â”‚
â”‚                      "doc_id": "doc2",                             â”‚
â”‚                      "score": 8.5,                                 â”‚
â”‚                      "text": "Retrieval Augmented Generation..."   â”‚
â”‚                    },                                              â”‚
â”‚                    ...                                             â”‚
â”‚                  ]                                                 â”‚
â”‚                                                                     â”‚
â”‚         D. Reciprocal Rank Fusion                                  â”‚
â”‚            â””â”€> RRF.fuse(                                          â”‚
â”‚                  vector_results=[...],                             â”‚
â”‚                  bm25_results=[...],                               â”‚
â”‚                  k=60                                              â”‚
â”‚                )                                                   â”‚
â”‚                Algorithm:                                          â”‚
â”‚                  for each result r in all_results:                 â”‚
â”‚                    score(r) = sum(1 / (k + rank(r, source)))       â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "doc_id": "doc1",                               â”‚
â”‚                    "rrf_score": 0.035,                             â”‚
â”‚                    "text": "RAG is Retrieval-Augmented...",        â”‚
â”‚                    "sources": ["vector", "bm25"]                   â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                                                                     â”‚
â”‚         E. Reranking (Cross-Encoder)                               â”‚
â”‚            â””â”€> Reranker.rerank(                                   â”‚
â”‚                  query="What is RAG?",                             â”‚
â”‚                  candidates=[...]                                  â”‚
â”‚                )                                                   â”‚
â”‚                Model: sentence-transformers/ms-marco-MiniLM        â”‚
â”‚                For each candidate:                                 â”‚
â”‚                  score = cross_encoder(query, candidate.text)      â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "doc_id": "doc1",                               â”‚
â”‚                    "rerank_score": 0.95,                           â”‚
â”‚                    "text": "RAG is Retrieval-Augmented..."         â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                                                                     â”‚
â”‚  7. Aggregator Node (Node: aggregate_results)                      â”‚
â”‚     â””â”€> Synthesize final answer                                   â”‚
â”‚         - Input: Top 5 reranked documents                          â”‚
â”‚         - Context: "RAG is Retrieval-Augmented Generation..."      â”‚
â”‚         - LLM Call: AegisLLMProxy (Sprint 25)                      â”‚
â”‚           proxy = get_aegis_llm_proxy()                            â”‚
â”‚           response = await proxy.complete(                         â”‚
â”‚             prompt="Answer based on context:\n[context]\n\n        â”‚
â”‚                     Question: What is RAG?",                       â”‚
â”‚             quality=QualityRequirement.MEDIUM,  # Generation task  â”‚
â”‚             task_type=TaskType.GENERATION                          â”‚
â”‚           )                                                        â”‚
â”‚           # Routes to local Ollama (llama3.2:8b) if available      â”‚
â”‚         - Response: {                                              â”‚
â”‚             "answer": "RAG (Retrieval-Augmented Generation)...",   â”‚
â”‚             "sources": ["doc1", "doc2"],                           â”‚
â”‚             "metadata": {...}                                      â”‚
â”‚           }                                                        â”‚
â”‚                                                                     â”‚
â”‚  8. State Update (Redis Checkpointer)                              â”‚
â”‚     â””â”€> Save conversation state                                   â”‚
â”‚         Redis SET session:abc123:state <pickled_state>             â”‚
â”‚         TTL: 86400 seconds (24 hours)                              â”‚
â”‚                                                                     â”‚
â”‚  9. HTTP Response                                                   â”‚
â”‚     â””â”€> FastAPI returns:                                          â”‚
â”‚         {                                                          â”‚
â”‚           "answer": "RAG (Retrieval-Augmented Generation)...",     â”‚
â”‚           "sources": [                                             â”‚
â”‚             {"file": "rag_overview.md", "score": 0.95},            â”‚
â”‚             {"file": "llama_index.md", "score": 0.88}              â”‚
â”‚           ],                                                       â”‚
â”‚           "session_id": "abc123",                                  â”‚
â”‚           "metadata": {                                            â”‚
â”‚             "tokens": 150,                                         â”‚
â”‚             "latency_ms": 450,                                     â”‚
â”‚             "rag_mode": "hybrid"                                   â”‚
â”‚           }                                                        â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  10. UI Update                                                      â”‚
â”‚      â””â”€> Gradio displays answer + sources                         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~450ms (with GPU)
- Embedding: 50ms
- Vector Search: 30ms
- BM25 Search: 20ms (parallel)
- RRF Fusion: 10ms
- Reranking: 50ms
- LLM Generation: 250ms (25 tokens @ 105 tokens/s)
- Overhead: 40ms
```

---

### Scenario 2: Graph RAG Query (Relationship Query)

**User Query:** "How are transformers related to attention mechanisms?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Graph RAG Query (Entity Relationships)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1-4. [Same as Scenario 1: User Input â†’ FastAPI â†’ LangGraph]       â”‚
â”‚                                                                     â”‚
â”‚  5. Router Agent (Node: route_query)                               â”‚
â”‚     â””â”€> Classify query type                                       â”‚
â”‚         - Input: "How are transformers related to attention?"      â”‚
â”‚         - LLM Classification: "RELATIONSHIP_QUERY"                 â”‚
â”‚         - Decision: Route to Graph Agent                           â”‚
â”‚                                                                     â”‚
â”‚  6. Graph Agent (Node: graph_search)                               â”‚
â”‚     â””â”€> LightRAG Dual-Level Retrieval                             â”‚
â”‚                                                                     â”‚
â”‚         A. Entity Extraction from Query                            â”‚
â”‚            â””â”€> LLM Call: AegisLLMProxy (Sprint 25)                â”‚
â”‚                proxy = get_aegis_llm_proxy()                       â”‚
â”‚                response = await proxy.complete(                    â”‚
â”‚                  prompt="Extract entities:\n                       â”‚
â”‚                          'How are transformers related to          â”‚
â”‚                           attention mechanisms?'",                 â”‚
â”‚                  quality=QualityRequirement.MEDIUM,                â”‚
â”‚                  task_type=TaskType.ENTITY_EXTRACTION              â”‚
â”‚                )                                                   â”‚
â”‚                # Uses extraction-optimized model (gemma-3-4b-it)   â”‚
â”‚                Response: {                                         â”‚
â”‚                  "entities": [                                     â”‚
â”‚                    {"text": "transformers", "type": "MODEL"},      â”‚
â”‚                    {"text": "attention mechanisms", "type":        â”‚
â”‚                     "TECHNIQUE"}                                   â”‚
â”‚                  ]                                                 â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚         B. Low-Level Retrieval (Entity Matching)                   â”‚
â”‚            â””â”€> Neo4j Cypher Query                                 â”‚
â”‚                Bolt Connection: localhost:7687                     â”‚
â”‚                Query:                                              â”‚
â”‚                  MATCH (e1:Entity {name: "transformers"})          â”‚
â”‚                  MATCH (e2:Entity {name: "attention mechanisms"})  â”‚
â”‚                  MATCH path = (e1)-[*1..3]-(e2)                    â”‚
â”‚                  RETURN path, relationships(path)                  â”‚
â”‚                  LIMIT 10                                          â”‚
â”‚                                                                     â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "path": [                                       â”‚
â”‚                      {entity: "transformers"},                     â”‚
â”‚                      {rel: "USES", weight: 0.9},                   â”‚
â”‚                      {entity: "attention mechanisms"}              â”‚
â”‚                    ]                                               â”‚
â”‚                  },                                                â”‚
â”‚                  {                                                 â”‚
â”‚                    "path": [                                       â”‚
â”‚                      {entity: "transformers"},                     â”‚
â”‚                      {rel: "COMPONENT_OF", weight: 0.8},           â”‚
â”‚                      {entity: "multi-head attention"},             â”‚
â”‚                      {rel: "IMPLEMENTS", weight: 0.95},            â”‚
â”‚                      {entity: "attention mechanisms"}              â”‚
â”‚                    ]                                               â”‚
â”‚                  }                                                 â”‚
â”‚                ]                                                   â”‚
â”‚                                                                     â”‚
â”‚         C. High-Level Retrieval (Topic/Community Matching)         â”‚
â”‚            â””â”€> Community Detection                                â”‚
â”‚                Neo4j Cypher Query:                                 â”‚
â”‚                  MATCH (e:Entity)-[:BELONGS_TO]->(c:Community)     â”‚
â”‚                  WHERE e.name IN ["transformers",                  â”‚
â”‚                                   "attention mechanisms"]          â”‚
â”‚                  RETURN c.topic, c.summary                         â”‚
â”‚                                                                     â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "topic": "Neural Network Architectures",        â”‚
â”‚                    "summary": "Transformers use attention          â”‚
â”‚                                mechanisms for sequence             â”‚
â”‚                                processing..."                      â”‚
â”‚                  }                                                 â”‚
â”‚                ]                                                   â”‚
â”‚                                                                     â”‚
â”‚         D. Combine Low-Level + High-Level Context                  â”‚
â”‚            â””â”€> Construct graph context:                           â”‚
â”‚                {                                                   â”‚
â”‚                  "entities": ["transformers", "attention"],        â”‚
â”‚                  "relationships": [                                â”‚
â”‚                    "transformers USES attention mechanisms",       â”‚
â”‚                    "transformers COMPONENT_OF multi-head           â”‚
â”‚                     attention"                                     â”‚
â”‚                  ],                                                â”‚
â”‚                  "community_summary": "Neural Network              â”‚
â”‚                    Architectures..."                               â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚  7. Aggregator Node (Node: aggregate_results)                      â”‚
â”‚     â””â”€> Synthesize answer with graph context                      â”‚
â”‚         - LLM Call: AegisLLMProxy (Sprint 25)                      â”‚
â”‚         - Context: Graph relationships + community summary         â”‚
â”‚         - Response: "Transformers are fundamentally built on       â”‚
â”‚                      attention mechanisms..."                      â”‚
â”‚                                                                     â”‚
â”‚  8-10. [Same as Scenario 1: State Update â†’ Response â†’ UI]          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~800ms (with GPU)
- Entity Extraction: 150ms
- Neo4j Low-Level Query: 200ms
- Neo4j High-Level Query: 150ms
- Context Construction: 50ms
- LLM Generation: 250ms
```

---

### Scenario 3: Memory-Augmented Query

**User Query:** "What did we discuss about RAG earlier?" (continuation of Scenario 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Memory-Augmented Query (3-Layer Memory)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1-5. [Same as previous: User Input â†’ Router]                      â”‚
â”‚       Router classifies as "MEMORY_QUERY"                          â”‚
â”‚                                                                     â”‚
â”‚  6. Memory Agent (Node: memory_search)                             â”‚
â”‚     â””â”€> 3-Layer Memory Lookup (Parallel)                          â”‚
â”‚                                                                     â”‚
â”‚         A. Layer 1: Redis (Short-Term Memory)                      â”‚
â”‚            â””â”€> Redis GET session:abc123:messages                  â”‚
â”‚                Redis Connection: localhost:6379                     â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "role": "user",                                 â”‚
â”‚                    "content": "What is RAG?",                      â”‚
â”‚                    "timestamp": "2025-10-22T10:15:00Z"             â”‚
â”‚                  },                                                â”‚
â”‚                  {                                                 â”‚
â”‚                    "role": "assistant",                            â”‚
â”‚                    "content": "RAG is Retrieval-Augmented...",     â”‚
â”‚                    "timestamp": "2025-10-22T10:15:02Z"             â”‚
â”‚                  }                                                 â”‚
â”‚                ]                                                   â”‚
â”‚                Latency: 5ms                                        â”‚
â”‚                                                                     â”‚
â”‚         B. Layer 2: Qdrant (Semantic Long-Term Memory)             â”‚
â”‚            â””â”€> Embed query: "What did we discuss about RAG?"      â”‚
â”‚                UnifiedEmbeddingService â†’ Ollama bge-m3 (Sprint 16) â”‚
â”‚                Vector: [0.234, -0.567, ...] (1024d)                â”‚
â”‚                                                                     â”‚
â”‚                QdrantClient.search(                                â”‚
â”‚                  collection="conversation-history",                â”‚
â”‚                  query_vector=[0.234, -0.567, ...],                â”‚
â”‚                  limit=5,                                          â”‚
â”‚                  filter={                                          â”‚
â”‚                    "session_id": "abc123",                         â”‚
â”‚                    "timestamp": {"$gte": "2025-10-21T00:00:00Z"}   â”‚
â”‚                  }                                                 â”‚
â”‚                )                                                   â”‚
â”‚                                                                     â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "conversation_id": "conv1",                     â”‚
â”‚                    "score": 0.88,                                  â”‚
â”‚                    "summary": "Discussed RAG definition and        â”‚
â”‚                                use cases"                          â”‚
â”‚                  }                                                 â”‚
â”‚                ]                                                   â”‚
â”‚                Latency: 30ms                                       â”‚
â”‚                                                                     â”‚
â”‚         C. Layer 3: Graphiti (Episodic Temporal Memory)            â”‚
â”‚            â””â”€> Graphiti.search(                                   â”‚
â”‚                  query="RAG discussion",                           â”‚
â”‚                  session_id="abc123",                              â”‚
â”‚                  temporal_filter={                                 â”‚
â”‚                    "valid_time": "2025-10-22T10:00:00Z"            â”‚
â”‚                  }                                                 â”‚
â”‚                )                                                   â”‚
â”‚                                                                     â”‚
â”‚                Neo4j Query (via Graphiti):                         â”‚
â”‚                  MATCH (e:Episode {session_id: "abc123"})          â”‚
â”‚                  WHERE e.valid_from <= timestamp() AND             â”‚
â”‚                        e.valid_to >= timestamp()                   â”‚
â”‚                  MATCH (e)-[:CONTAINS]->(f:Fact)                   â”‚
â”‚                  WHERE f.text CONTAINS "RAG"                       â”‚
â”‚                  RETURN e, f                                       â”‚
â”‚                                                                     â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "episode_id": "ep1",                            â”‚
â”‚                    "facts": [                                      â”‚
â”‚                      "User asked about RAG definition",            â”‚
â”‚                      "Assistant explained RAG components"          â”‚
â”‚                    ],                                              â”‚
â”‚                    "timestamp": "2025-10-22T10:15:00Z"             â”‚
â”‚                  }                                                 â”‚
â”‚                ]                                                   â”‚
â”‚                Latency: 150ms                                      â”‚
â”‚                                                                     â”‚
â”‚         D. Memory Fusion                                           â”‚
â”‚            â””â”€> Combine all 3 layers:                              â”‚
â”‚                {                                                   â”‚
â”‚                  "recent_context": [Redis messages],               â”‚
â”‚                  "similar_conversations": [Qdrant results],        â”‚
â”‚                  "episodic_facts": [Graphiti facts]                â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚  7. Aggregator Node                                                â”‚
â”‚     â””â”€> Synthesize answer using memory context                    â”‚
â”‚         - LLM sees recent conversation from Redis                  â”‚
â”‚         - LLM sees similar past conversations from Qdrant          â”‚
â”‚         - LLM sees extracted facts from Graphiti                   â”‚
â”‚         - Response: "Earlier we discussed that RAG is              â”‚
â”‚                      Retrieval-Augmented Generation, which..."     â”‚
â”‚                                                                     â”‚
â”‚  8-10. [State Update â†’ Response â†’ UI]                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~350ms
- Redis Lookup: 5ms
- Qdrant Lookup: 30ms (parallel)
- Graphiti Lookup: 150ms (parallel)
- Fusion: 15ms
- LLM Generation: 150ms
```

---

### Scenario 4: Document Ingestion Flow

**User Action:** Upload PDF document "transformer_paper.pdf"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Document Ingestion (Parallel Indexing)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. User Upload                                                     â”‚
â”‚     â””â”€> Gradio UI: File.upload("transformer_paper.pdf")           â”‚
â”‚                                                                     â”‚
â”‚  2. HTTP Request                                                    â”‚
â”‚     â””â”€> POST http://localhost:8000/api/v1/documents/upload        â”‚
â”‚         Content-Type: multipart/form-data                          â”‚
â”‚         File: transformer_paper.pdf (5MB)                          â”‚
â”‚                                                                     â”‚
â”‚  3. FastAPI Handler                                                 â”‚
â”‚     â””â”€> async def upload_document(file: UploadFile)               â”‚
â”‚         - Save to temp: /tmp/transformer_paper.pdf                 â”‚
â”‚         - Validate: PDF, <10MB                                     â”‚
â”‚         - Security: Path traversal check                           â”‚
â”‚                                                                     â”‚
â”‚  4. LangGraph Ingestion Pipeline (Sprint 21-22)                    â”‚
â”‚     â””â”€> create_ingestion_graph().ainvoke(initial_state)          â”‚
â”‚                                                                     â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚         â”‚   Sequential Execution (LangGraph StateGraph)       â”‚   â”‚
â”‚         â”‚   (Memory-optimized: 4.4GB RAM, 6GB VRAM)           â”‚   â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 1: memory_check_node (5% progress)           â”‚   â”‚
â”‚         â”‚     â””â”€> Check document already indexed             â”‚   â”‚
â”‚         â”‚         Neo4j query: MATCH (d:Document {hash: ...}) â”‚   â”‚
â”‚         â”‚         Decision: Skip if duplicate                 â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 2: format_routing_node (10% progress)        â”‚   â”‚
â”‚         â”‚     â””â”€> FormatRouter.route(document_path)          â”‚   â”‚
â”‚         â”‚         Decision: Docling vs LlamaIndex            â”‚   â”‚
â”‚         â”‚         30+ formats supported (Sprint 22.3)         â”‚   â”‚
â”‚         â”‚         - Docling: 14 formats (PDF, DOCX, PPTX...) â”‚   â”‚
â”‚         â”‚         - LlamaIndex: 9 formats (CSV, Markdown...) â”‚   â”‚
â”‚         â”‚         - Shared: 7 formats (fallback logic)       â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 3a: docling_parse_node (30% progress)        â”‚   â”‚
â”‚         â”‚     â””â”€> DoclingContainerClient.parse(pdf)          â”‚   â”‚
â”‚         â”‚         GPU-accelerated OCR (EasyOCR)              â”‚   â”‚
â”‚         â”‚         Table structure preservation (92% accuracy) â”‚   â”‚
â”‚         â”‚         Performance: 420s â†’ 120s (3.5x speedup)    â”‚   â”‚
â”‚         â”‚         Raw text: "Attention Is All You Need..."    â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 3b: llamaindex_parse_node (fallback)         â”‚   â”‚
â”‚         â”‚     â””â”€> LlamaIndexParser.parse(csv)                â”‚   â”‚
â”‚         â”‚         SimpleDirectoryReader.load_data()           â”‚   â”‚
â”‚         â”‚         Connector library (300+ sources)            â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 4: chunking_node (45% progress)              â”‚   â”‚
â”‚         â”‚     â””â”€> ChunkingService.chunk(                    â”‚   â”‚
â”‚         â”‚           text=parsed_text,                        â”‚   â”‚
â”‚         â”‚           strategy="adaptive"  # Document-aware    â”‚   â”‚
â”‚         â”‚         )                                          â”‚   â”‚
â”‚         â”‚         Unified chunks with SHA-256 IDs (Sprint 16) â”‚   â”‚
â”‚         â”‚         Chunks: [Chunk(id="a3f2e1d9", text=...)]   â”‚   â”‚
â”‚         â”‚         # 45 chunks created                        â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 5: embedding_node (75% progress)             â”‚   â”‚
â”‚         â”‚     â””â”€> UnifiedEmbeddingService.embed_batch([     â”‚   â”‚
â”‚         â”‚           "Abstract: The dominant...",             â”‚   â”‚
â”‚         â”‚           "Introduction: Recurrent...",            â”‚   â”‚
â”‚         â”‚           ...  # batch of 32 (Sprint 16)           â”‚   â”‚
â”‚         â”‚         ])                                         â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚         Ollama API Call:                           â”‚   â”‚
â”‚         â”‚         POST http://localhost:11434/api/embeddings â”‚   â”‚
â”‚         â”‚         Body: {                                    â”‚   â”‚
â”‚         â”‚           "model": "bge-m3",  # 1024-dim (Sprint 16) â”‚   â”‚
â”‚         â”‚           "inputs": [...]  # batch of 32           â”‚   â”‚
â”‚         â”‚         }                                          â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚         Response: [                                â”‚   â”‚
â”‚         â”‚           [0.123, -0.456, ...],  # 1024d           â”‚   â”‚
â”‚         â”‚           [0.234, -0.567, ...],                    â”‚   â”‚
â”‚         â”‚           ...                                      â”‚   â”‚
â”‚         â”‚         ]                                          â”‚   â”‚
â”‚         â”‚         Cache: Store in LRU cache                  â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚         Upload to Qdrant + BM25:                   â”‚   â”‚
â”‚         â”‚         QdrantClient.upsert(                       â”‚   â”‚
â”‚         â”‚           collection="aegis-rag-documents",        â”‚   â”‚
â”‚         â”‚           points=[{id, vector, payload}, ...]      â”‚   â”‚
â”‚         â”‚         )                                          â”‚   â”‚
â”‚         â”‚         BM25Search.add_documents([...])            â”‚   â”‚
â”‚         â”‚         Latency: ~2s for 45 chunks                 â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚  Node 6: graph_extraction_node (100% progress)     â”‚   â”‚
â”‚         â”‚     â””â”€> LightRAG Entity Extraction                â”‚   â”‚
â”‚         â”‚         For each chunk:                            â”‚   â”‚
â”‚         â”‚         AegisLLMProxy.complete(                    â”‚   â”‚
â”‚         â”‚           prompt="Extract entities from chunk...", â”‚   â”‚
â”‚         â”‚           quality=QualityRequirement.MEDIUM,       â”‚   â”‚
â”‚         â”‚           task_type=TaskType.ENTITY_EXTRACTION     â”‚   â”‚
â”‚         â”‚         )                                          â”‚   â”‚
â”‚         â”‚         # Uses gemma-3-4b-it (extraction-optimized) â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚         Entities extracted: [                      â”‚   â”‚
â”‚         â”‚           {"text": "Transformer", "type": "MODEL"} â”‚   â”‚
â”‚         â”‚           {"text": "Attention Mechanism", ...}     â”‚   â”‚
â”‚         â”‚         ]                                          â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚         Store in Neo4j:                            â”‚   â”‚
â”‚         â”‚         MERGE (e:Entity {name: "Transformer"})     â”‚   â”‚
â”‚         â”‚         MERGE (s)-[r:USES]->(t)                    â”‚   â”‚
â”‚         â”‚         SET r.weight = 0.9                         â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â”‚         Community Detection:                       â”‚   â”‚
â”‚         â”‚         CALL gds.leiden.stream(...)                â”‚   â”‚
â”‚         â”‚         Latency: ~8s for 45 chunks                 â”‚   â”‚
â”‚         â”‚                                                     â”‚   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â”‚  5. Progress Tracking                                               â”‚
â”‚     â””â”€> WebSocket updates to UI:                                  â”‚
â”‚         {                                                          â”‚
â”‚           "status": "indexing",                                    â”‚
â”‚           "overall_progress": 0.75,  # 75% complete               â”‚
â”‚           "current_node": "embedding_node",                        â”‚
â”‚           "chunks_processed": 45,                                  â”‚
â”‚           "entities_extracted": 0  # Not yet reached graph node    â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  6. Completion Response                                             â”‚
â”‚     â””â”€> HTTP 200 OK                                               â”‚
â”‚         {                                                          â”‚
â”‚           "status": "success",                                     â”‚
â”‚           "filename": "transformer_paper.pdf",                     â”‚
â”‚           "chunks_created": 45,                                    â”‚
â”‚           "entities_extracted": 87,                                â”‚
â”‚           "relationships_created": 124,                            â”‚
â”‚           "indexing_time_ms": 10000,                               â”‚
â”‚           "doc_hash": "sha256..."                                  â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  7. UI Update                                                       â”‚
â”‚     â””â”€> Gradio shows success message                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~12s (Sequential LangGraph Pipeline, Sprint 21-22)
- Memory Check: ~100ms (Neo4j query)
- Format Routing: ~50ms (rule-based decision)
- Docling Parse: ~3s (GPU-accelerated OCR)
- Chunking: ~500ms (adaptive strategy)
- Embedding: ~2s (BGE-M3, batch of 32)
- Qdrant + BM25: ~1s (parallel upload)
- Graph Extraction: ~5s (LLM entity extraction + Neo4j)
- Community Detection: ~500ms (Leiden algorithm)

Sprint 21 Improvements:
- 3.5x faster parsing (Docling vs LlamaIndex: 120s vs 420s)
- 95% OCR accuracy (EasyOCR GPU vs 70% LlamaIndex)
- 92% table structure preservation
- 30+ format support (FormatRouter Sprint 22.3)
```

---

### Scenario 5: Unified Re-Indexing with BGE-M3 (Sprint 16)

**Admin Action:** Trigger full re-indexing after BGE-M3 migration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Unified Re-Indexing (Admin Endpoint)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. Admin Request                                                   â”‚
â”‚     â””â”€> POST /api/v1/admin/reindex?confirm=true                   â”‚
â”‚         Headers: Accept: text/event-stream                          â”‚
â”‚                                                                     â”‚
â”‚  2. Phase 1: Initialization (SSE Event)                             â”‚
â”‚     â””â”€> Validate parameters, load document list                    â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "initialization",                                â”‚
â”‚           "documents_total": 933                                    â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  3. Phase 2: Atomic Deletion (SSE Event)                            â”‚
â”‚     â””â”€> Delete all indexes (all-or-nothing):                      â”‚
â”‚         A. Qdrant: DELETE collection "aegis-rag-documents"         â”‚
â”‚         B. BM25: DELETE cache "bm25_index.pkl"                     â”‚
â”‚         C. (Neo4j graph deletion pending Feature 16.6)             â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "deletion",                                      â”‚
â”‚           "message": "Deleted Qdrant + BM25 indexes"               â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  4. Phase 3: Unified Chunking (SSE Events)                          â”‚
â”‚     â””â”€> For each document (parallel batches of 10):               â”‚
â”‚                                                                     â”‚
â”‚         ChunkingService.chunk(                                      â”‚
â”‚           text=document.text,                                       â”‚
â”‚           strategy="adaptive",  # Document-aware                   â”‚
â”‚           max_tokens=512,                                          â”‚
â”‚           overlap=128                                              â”‚
â”‚         )                                                          â”‚
â”‚           â†“                                                        â”‚
â”‚         Chunks with SHA-256 IDs:                                   â”‚
â”‚         [                                                          â”‚
â”‚           Chunk(                                                   â”‚
â”‚             chunk_id="a3f2e1d9c8b7",  # Deterministic SHA-256     â”‚
â”‚             text="Abstract: The dominant...",                      â”‚
â”‚             source="transformer_paper.pdf",                        â”‚
â”‚             position=0,                                            â”‚
â”‚             tokens=487                                             â”‚
â”‚           ),                                                       â”‚
â”‚           ...                                                      â”‚
â”‚         ]                                                          â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "chunking",                                      â”‚
â”‚           "documents_processed": 450,                               â”‚
â”‚           "documents_total": 933,                                   â”‚
â”‚           "progress_percent": 48.2,                                 â”‚
â”‚           "eta_seconds": 1200,                                      â”‚
â”‚           "current_document": "transformer_paper.pdf"               â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  5. Phase 4: BGE-M3 Embedding Generation (SSE Events)               â”‚
â”‚     â””â”€> For each chunk (batch of 32):                             â”‚
â”‚                                                                     â”‚
â”‚         UnifiedEmbeddingService.embed_batch([                       â”‚
â”‚           "Abstract: The dominant...",                              â”‚
â”‚           "Introduction: Recurrent...",                             â”‚
â”‚           ...  # 32 chunks                                         â”‚
â”‚         ])                                                         â”‚
â”‚           â†“                                                        â”‚
â”‚         Ollama API Call:                                           â”‚
â”‚         POST http://localhost:11434/api/embed                      â”‚
â”‚         Body: {                                                    â”‚
â”‚           "model": "bge-m3",  # 1024-dim                           â”‚
â”‚           "inputs": [...]                                          â”‚
â”‚         }                                                          â”‚
â”‚           â†“                                                        â”‚
â”‚         Response: [                                                â”‚
â”‚           [0.123, -0.456, ..., 0.789],  # 1024-dim                 â”‚
â”‚           [0.234, -0.567, ..., 0.890],                             â”‚
â”‚           ...                                                      â”‚
â”‚         ]                                                          â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "embedding",                                     â”‚
â”‚           "chunks_processed": 2800,                                 â”‚
â”‚           "chunks_total": 10000,                                    â”‚
â”‚           "progress_percent": 28.0,                                 â”‚
â”‚           "eta_seconds": 2400                                       â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  6. Phase 5: Multi-Index Insertion (SSE Events)                     â”‚
â”‚     â””â”€> Insert into all indexes (parallel):                       â”‚
â”‚                                                                     â”‚
â”‚         A. Qdrant Insertion                                         â”‚
â”‚            â””â”€> QdrantClient.upsert(                               â”‚
â”‚                  collection="aegis-rag-documents",                  â”‚
â”‚                  points=[                                          â”‚
â”‚                    {                                               â”‚
â”‚                      "id": "a3f2e1d9c8b7",  # SHA-256             â”‚
â”‚                      "vector": [0.123, ..., 0.789],  # 1024-dim    â”‚
â”‚                      "payload": {                                  â”‚
â”‚                        "text": "Abstract: The...",                 â”‚
â”‚                        "source": "transformer_paper.pdf",          â”‚
â”‚                        "chunk_id": "a3f2e1d9c8b7"                  â”‚
â”‚                      }                                             â”‚
â”‚                    },                                              â”‚
â”‚                    ...                                             â”‚
â”‚                  ]                                                 â”‚
â”‚                )                                                   â”‚
â”‚                                                                     â”‚
â”‚         B. BM25 Indexing (Automatic via Qdrant sync)                â”‚
â”‚            â””â”€> BM25 automatically synchronized                    â”‚
â”‚                No separate indexing needed                         â”‚
â”‚                                                                     â”‚
â”‚         C. LightRAG (Feature 16.6 - uses unified chunks)            â”‚
â”‚            â””â”€> Entity extraction per chunk                        â”‚
â”‚                Neo4j stores chunk_id in :MENTIONED_IN              â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "indexing",                                      â”‚
â”‚           "indexes": {                                             â”‚
â”‚             "qdrant": "complete",                                  â”‚
â”‚             "bm25": "complete",                                    â”‚
â”‚             "neo4j": "pending"                                     â”‚
â”‚           }                                                        â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  7. Phase 6: Validation (SSE Event)                                 â”‚
â”‚     â””â”€> Verify index consistency:                                 â”‚
â”‚         - Qdrant point count == chunk count                        â”‚
â”‚         - BM25 document count == document count                    â”‚
â”‚         - Neo4j entity count > 0                                   â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "complete",                                     â”‚
â”‚           "phase": "validation",                                    â”‚
â”‚           "summary": {                                             â”‚
â”‚             "documents_processed": 933,                             â”‚
â”‚             "chunks_created": 10234,                                â”‚
â”‚             "qdrant_points": 10234,                                 â”‚
â”‚             "bm25_docs": 933,                                       â”‚
â”‚             "neo4j_entities": 1587,                                 â”‚
â”‚             "total_time_seconds": 8940,                             â”‚
â”‚             "embedding_model": "bge-m3",                            â”‚
â”‚             "embedding_dim": 1024                                   â”‚
â”‚           }                                                        â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  8. Admin Dashboard Update                                          â”‚
â”‚     â””â”€> Display completion summary                                â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~2.5 hours (9,000 seconds)
- Deletion: ~30s (atomic)
- Chunking: ~1,500s (933 docs â†’ 10K chunks)
- Embedding: ~6,000s (10K chunks Ã— 25ms/chunk BGE-M3)
- Indexing: ~1,400s (parallel: Qdrant + BM25)
- Validation: ~10s

Key Improvements (Sprint 16):
- Unified chunks (ChunkingService) â†’ consistent provenance
- BGE-M3 embeddings (1024-dim) â†’ cross-layer similarity
- SSE progress â†’ real-time visibility
- Atomic deletion â†’ no inconsistent state
- Safety checks â†’ confirm=true required
```

---

### Scenario 6: Knowledge Graph Deduplication Pipeline (Sprint 49)

**Admin Action:** Run deduplication after document ingestion to resolve duplicate entities and relations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Knowledge Graph Deduplication (Entity + Relation Dedup)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. Admin Request                                                   â”‚
â”‚     â””â”€> POST /api/v1/admin/deduplicate-graph?confirm=true         â”‚
â”‚         Headers: Accept: text/event-stream                          â”‚
â”‚                                                                     â”‚
â”‚  2. Phase 1: Data Collection (SSE Event)                            â”‚
â”‚     â””â”€> Load all entities and relations from Neo4j                 â”‚
â”‚         Neo4j Query:                                                â”‚
â”‚         MATCH (e:Entity) RETURN e                                   â”‚
â”‚         MATCH (e1)-[r:RELATES_TO]->(e2) RETURN r                   â”‚
â”‚                                                                     â”‚
â”‚         Response: 1,587 entities, 2,445 relations                   â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "data_collection",                               â”‚
â”‚           "entities_loaded": 1587,                                  â”‚
â”‚           "relations_loaded": 2445                                  â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  3. Phase 2: Entity Deduplication (Sprint 49.9) (SSE Events)       â”‚
â”‚     â””â”€> Identify and merge duplicate entities                      â”‚
â”‚                                                                     â”‚
â”‚         A. Batch Embedding Generation                              â”‚
â”‚            â””â”€> UnifiedEmbeddingService.embed_batch([               â”‚
â”‚                  "Transformer",                                     â”‚
â”‚                  "Transformers",  # Similar entity                  â”‚
â”‚                  "TransformerModel",  # Another variant             â”‚
â”‚                  ...  # All 1,587 entity names                      â”‚
â”‚                ])                                                   â”‚
â”‚                                                                     â”‚
â”‚                Ollama API Call (bge-m3):                            â”‚
â”‚                POST http://localhost:11434/api/embeddings          â”‚
â”‚                Response: [                                          â”‚
â”‚                  [0.123, -0.456, ...],  # "Transformer"            â”‚
â”‚                  [0.125, -0.450, ...],  # "Transformers" (similar) â”‚
â”‚                  [0.128, -0.452, ...],  # "TransformerModel"       â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                Latency: 3s for 1,587 entities                       â”‚
â”‚                                                                     â”‚
â”‚         B. Cosine Similarity Computation                            â”‚
â”‚            â””â”€> Compute pairwise similarities                       â”‚
â”‚                For all pairs (e1, e2):                              â”‚
â”‚                  similarity = cosine_distance(embed[e1], embed[e2]) â”‚
â”‚                Results: 2M+ comparisons                             â”‚
â”‚                Latency: 2s (vectorized)                             â”‚
â”‚                                                                     â”‚
â”‚         C. Duplicate Detection (0.85 threshold)                     â”‚
â”‚            â””â”€> Group similar entities                              â”‚
â”‚                Clusters: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "canonical": "Transformer",  # Most frequent     â”‚
â”‚                    "variants": ["Transformers", "TransformerModel"] â”‚
â”‚                    "similarities": [0.88, 0.86]  # >= 0.85          â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                Duplicates Found: 234 entities                       â”‚
â”‚                                                                     â”‚
â”‚         D. Canonical Entity Mapping                                 â”‚
â”‚            â””â”€> Create dedup_map: variant â†’ canonical                â”‚
â”‚                {                                                   â”‚
â”‚                  "Transformers": "Transformer",                     â”‚
â”‚                  "TransformerModel": "Transformer",                 â”‚
â”‚                  "attention head": "Attention Mechanism",           â”‚
â”‚                  ...                                               â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "entity_deduplication",                          â”‚
â”‚           "duplicates_found": 234,                                  â”‚
â”‚           "similarity_threshold": 0.85,                             â”‚
â”‚           "dedup_map_size": 234                                     â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  4. Phase 3: Relation Extraction & Deduplication (Sprint 49.7)      â”‚
â”‚     â””â”€> Identify and merge duplicate relations                     â”‚
â”‚                                                                     â”‚
â”‚         A. Relation Type Extraction                                 â”‚
â”‚            â””â”€> Extract relation types: [                           â”‚
â”‚                  "USES",                                            â”‚
â”‚                  "uses",  # Variant                                 â”‚
â”‚                  "RELATED_TO",                                      â”‚
â”‚                  "related-to",  # Another variant                   â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                Unique types: 47                                     â”‚
â”‚                                                                     â”‚
â”‚         B. Relation Type Embedding                                  â”‚
â”‚            â””â”€> Embed relation types (BGE-M3)                       â”‚
â”‚                UnifiedEmbeddingService.embed_batch([                â”‚
â”‚                  "USES",                                            â”‚
â”‚                  "uses",                                            â”‚
â”‚                  "RELATED_TO",                                      â”‚
â”‚                  ...                                               â”‚
â”‚                ])                                                   â”‚
â”‚                Response: [0.234, -0.567, ...] per type              â”‚
â”‚                Latency: 200ms                                       â”‚
â”‚                                                                     â”‚
â”‚         C. Hierarchical Clustering (0.88 threshold)                 â”‚
â”‚            â””â”€> Group similar relation types                        â”‚
â”‚                Algorithm: Hierarchical clustering with linkage      â”‚
â”‚                Clusters: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "canonical": "USES",                             â”‚
â”‚                    "variants": ["uses", "USES"],                    â”‚
â”‚                    "similarities": [0.95, 0.99]  # >= 0.88          â”‚
â”‚                  },                                                â”‚
â”‚                  {                                                 â”‚
â”‚                    "canonical": "RELATED_TO",                       â”‚
â”‚                    "variants": ["related-to", "RELATES_TO"],        â”‚
â”‚                    "similarities": [0.91, 0.92]  # >= 0.88          â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                Type synonyms Found: 12                              â”‚
â”‚                                                                     â”‚
â”‚         D. Relation Type Synonym Mapping                            â”‚
â”‚            â””â”€> Create type_synonym_map                              â”‚
â”‚                {                                                   â”‚
â”‚                  "uses": "USES",                                     â”‚
â”‚                  "USES": "USES",                                     â”‚
â”‚                  "related-to": "RELATED_TO",                        â”‚
â”‚                  "RELATES_TO": "RELATED_TO",                        â”‚
â”‚                  ...                                               â”‚
â”‚                }                                                   â”‚
â”‚                Store in Redis (Sprint 49.8):                        â”‚
â”‚                HSET graph:relation-synonyms "uses" "USES"           â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "relation_deduplication",                        â”‚
â”‚           "type_synonyms_found": 12,                                â”‚
â”‚           "clustering_threshold": 0.88                              â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  5. Phase 4: Relation Normalization (Sprint 49.3)                   â”‚
â”‚     â””â”€> Apply dedup maps to normalize graph                        â”‚
â”‚                                                                     â”‚
â”‚         A. Entity Name Remapping                                    â”‚
â”‚            â””â”€> For each relation:                                  â”‚
â”‚                OLD: (Transformers)-[USES]->(attention head)         â”‚
â”‚                MAP: Transformers â†’ Transformer                      â”‚
â”‚                     attention head â†’ Attention Mechanism            â”‚
â”‚                NEW: (Transformer)-[USES]->(Attention Mechanism)     â”‚
â”‚                                                                     â”‚
â”‚         B. Relation Type Normalization                              â”‚
â”‚            â””â”€> For each relation:                                  â”‚
â”‚                OLD: (source)-[uses]->(target)                       â”‚
â”‚                MAP: uses â†’ USES                                     â”‚
â”‚                NEW: (source)-[USES]->(target)                       â”‚
â”‚                                                                     â”‚
â”‚         C. Symmetric Relation Handling                              â”‚
â”‚            â””â”€> Detect bidirectional relations:                     â”‚
â”‚                MATCH (e1)-[r1:RELATES_TO]->(e2),                   â”‚
â”‚                       (e2)-[r2:RELATES_TO]->(e1)                   â”‚
â”‚                Decision: Keep only one direction (e1â†’e2)            â”‚
â”‚                Merge weights: weight = (r1.weight + r2.weight)/2   â”‚
â”‚                                                                     â”‚
â”‚         D. Final Deduplication                                      â”‚
â”‚            â””â”€> GROUP BY (source_entity, target_entity, type)        â”‚
â”‚                For duplicates:                                      â”‚
â”‚                  OLD: 2x (Transformer)-[USES]â†’(Attention)           â”‚
â”‚                       with weights [0.9, 0.85]                      â”‚
â”‚                  NEW: 1x (Transformer)-[USES]â†’(Attention)           â”‚
â”‚                       with weight = max(0.9, 0.85) = 0.9            â”‚
â”‚                Relations Merged: 156                                 â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "relation_normalization",                        â”‚
â”‚           "entities_remapped": 234,                                 â”‚
â”‚           "relation_types_normalized": 47,                          â”‚
â”‚           "symmetric_relations_resolved": 45,                       â”‚
â”‚           "relations_merged": 156                                   â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  6. Phase 5: Neo4j Updates (SSE Event)                              â”‚
â”‚     â””â”€> Apply normalized data to Neo4j                             â”‚
â”‚                                                                     â”‚
â”‚         A. Merge Duplicate Entities                                 â”‚
â”‚            â””â”€> For each duplicate cluster:                         â”‚
â”‚                Neo4j Cypher:                                        â”‚
â”‚                MATCH (canonical:Entity {name: "Transformer"})       â”‚
â”‚                MATCH (dup:Entity {name: "Transformers"})            â”‚
â”‚                SET canonical.aliases = ['Transformers']             â”‚
â”‚                MATCH (dup)-[r]->(target)                            â”‚
â”‚                CREATE (canonical)-[COPY OF r]-(target)              â”‚
â”‚                SET canonical.confidence = max(...)                  â”‚
â”‚                DELETE dup                                           â”‚
â”‚                Entities Deleted: 234                                â”‚
â”‚                Entities Updated: 1,353                              â”‚
â”‚                                                                     â”‚
â”‚         B. Normalize Relations                                      â”‚
â”‚            â””â”€> Delete old relations, create normalized ones         â”‚
â”‚                Relations Deleted: 2,445                             â”‚
â”‚                Relations Created: 2,289 (merged + normalized)       â”‚
â”‚                Net Reduction: 156 relations                         â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "in_progress",                                  â”‚
â”‚           "phase": "neo4j_update",                                  â”‚
â”‚           "entities_deleted": 234,                                  â”‚
â”‚           "entities_updated": 1353,                                 â”‚
â”‚           "relations_deleted": 2445,                                â”‚
â”‚           "relations_created": 2289                                 â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  7. Phase 6: Index Consistency Validation (Sprint 49.6)             â”‚
â”‚     â””â”€> Verify graph consistency after dedup                       â”‚
â”‚                                                                     â”‚
â”‚         A. Cross-Reference Check                                    â”‚
â”‚            â””â”€> Verify all Neo4j entities are in Qdrant             â”‚
â”‚                For each entity:                                     â”‚
â”‚                  1. Get entity name                                 â”‚
â”‚                  2. Embed name (BGE-M3)                             â”‚
â”‚                  3. Search Qdrant for documents mentioning entity    â”‚
â”‚                  4. Verify MENTIONED_IN relation exists             â”‚
â”‚                                                                     â”‚
â”‚         B. Orphan Detection                                         â”‚
â”‚            â””â”€> Find entities without source chunks                 â”‚
â”‚                Neo4j Query:                                         â”‚
â”‚                MATCH (e:Entity)                                     â”‚
â”‚                WHERE NOT (e)-[:MENTIONED_IN]->()                    â”‚
â”‚                RETURN e                                             â”‚
â”‚                Orphaned Entities: 0                                  â”‚
â”‚                                                                     â”‚
â”‚         C. Validation Report                                        â”‚
â”‚            â””â”€> Generate consistency report:                         â”‚
â”‚                {                                                   â”‚
â”‚                  "consistency_score": 0.98,  # 98% consistent       â”‚
â”‚                  "total_entities": 1353,                            â”‚
â”‚                  "total_relations": 2289,                           â”‚
â”‚                  "orphaned_entities": 0,                            â”‚
â”‚                  "orphaned_chunks": 0,                              â”‚
â”‚                  "status": "healthy"                                â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚         SSE: {                                                      â”‚
â”‚           "status": "complete",                                     â”‚
â”‚           "phase": "validation",                                    â”‚
â”‚           "consistency_score": 0.98,                                â”‚
â”‚           "summary": {                                              â”‚
â”‚             "entities_before": 1587,                                â”‚
â”‚             "entities_after": 1353,                                 â”‚
â”‚             "entities_deduplicated": 234,                           â”‚
â”‚             "relations_before": 2445,                               â”‚
â”‚             "relations_after": 2289,                                â”‚
â”‚             "relations_merged": 156,                                â”‚
â”‚             "total_time_seconds": 45,                               â”‚
â”‚             "dedup_status": "success"                               â”‚
â”‚           }                                                        â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~45s
- Data Collection: 2s (Neo4j query)
- Entity Embedding: 3s (1,587 entities)
- Similarity Computation: 2s (vectorized)
- Duplicate Detection: 1s (clustering)
- Relation Embedding: 200ms (47 types)
- Clustering: 1s (hierarchical)
- Neo4j Updates: 20s (transaction)
- Validation: 15s (consistency check)

Key Improvements (Sprint 49):
- Entity deduplication via semantic embeddings (0.85 threshold)
- Relation type normalization (0.88 clustering threshold)
- Orphan detection and validation reporting
- Redis synonym overrides for manual curation (Sprint 49.8)
- Atomic transaction rollback on validation failure
```

---

### Scenario 7: Index Consistency Validation (Sprint 49.6)

**Admin Action:** Validate cross-index consistency between Qdrant, Neo4j, and source chunks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Index Consistency Validation                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. Admin Request                                                   â”‚
â”‚     â””â”€> GET /api/v1/admin/validate-consistency                     â”‚
â”‚         Query Params: ?full=true (detailed check) | false (summary) â”‚
â”‚                                                                     â”‚
â”‚  2. Data Collection Phase                                           â”‚
â”‚     â””â”€> Load all indexes in parallel                               â”‚
â”‚                                                                     â”‚
â”‚         A. Qdrant Collection Query                                  â”‚
â”‚            â””â”€> QdrantClient.scroll(                                â”‚
â”‚                  collection="aegis-rag-documents",                  â”‚
â”‚                  limit=10000                                        â”‚
â”‚                )                                                   â”‚
â”‚                Response: [                                         â”‚
â”‚                  {                                                 â”‚
â”‚                    "id": "chunk_abc123",                            â”‚
â”‚                    "vector": [...],                                 â”‚
â”‚                    "payload": {                                    â”‚
â”‚                      "text": "...",                                 â”‚
â”‚                      "source": "doc.pdf",                           â”‚
â”‚                      "chunk_id": "chunk_abc123"                     â”‚
â”‚                    }                                               â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                Total Chunks: 10,234                                 â”‚
â”‚                                                                     â”‚
â”‚         B. Neo4j Entity Query                                       â”‚
â”‚            â””â”€> MATCH (e:Entity) RETURN e                           â”‚
â”‚                Response: 1,353 entities                             â”‚
â”‚                MATCH (e)-[:MENTIONED_IN]->(c:Chunk)                â”‚
â”‚                Response: 2,156 (entityâ†’chunk) links                â”‚
â”‚                                                                     â”‚
â”‚         C. Neo4j Relation Query                                     â”‚
â”‚            â””â”€> MATCH (e1)-[r:RELATES_TO]->(e2)                    â”‚
â”‚                RETURN r                                             â”‚
â”‚                Response: 2,289 relations                            â”‚
â”‚                                                                     â”‚
â”‚  3. Validation Phase 1: Chunk Presence                              â”‚
â”‚     â””â”€> Verify all Neo4j chunks exist in Qdrant                    â”‚
â”‚                                                                     â”‚
â”‚         For each chunk in Neo4j:                                    â”‚
â”‚           1. Check chunk exists in Qdrant (by ID)                   â”‚
â”‚           2. Verify payload consistency (text, source)              â”‚
â”‚           3. Count mismatches                                       â”‚
â”‚                                                                     â”‚
â”‚         Results: {                                                 â”‚
â”‚           "missing_in_qdrant": 0,  # OK                             â”‚
â”‚           "payload_mismatches": 0   # OK                            â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  4. Validation Phase 2: Entity â†’ Chunk Mapping                      â”‚
â”‚     â””â”€> Verify source_chunk_id references (Sprint 49.5)            â”‚
â”‚                                                                     â”‚
â”‚         For each entity:                                            â”‚
â”‚           1. Check MENTIONED_IN relation exists                     â”‚
â”‚           2. Verify target chunk exists in Qdrant                   â”‚
â”‚           3. Verify entity text is in chunk text                    â”‚
â”‚                                                                     â”‚
â”‚         Results: {                                                 â”‚
â”‚           "orphaned_entities": 0,  # Entities with no chunks        â”‚
â”‚           "invalid_mentions": 0    # Chunk references missing       â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  5. Validation Phase 3: Relation Integrity                          â”‚
â”‚     â””â”€> Verify RELATES_TO relations are valid                      â”‚
â”‚                                                                     â”‚
â”‚         For each relation (e1â†’e2):                                  â”‚
â”‚           1. Verify both entities exist in Neo4j                    â”‚
â”‚           2. Verify both entities have MENTIONED_IN chunks          â”‚
â”‚           3. Verify relation type is valid                          â”‚
â”‚           4. Verify weight in [0, 1]                                â”‚
â”‚                                                                     â”‚
â”‚         Results: {                                                 â”‚
â”‚           "dangling_relations": 0,  # Relations with missing nodes  â”‚
â”‚           "invalid_weights": 0,     # Out of range weights          â”‚
â”‚           "invalid_types": 0        # Unknown relation types        â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  6. Validation Report                                               â”‚
â”‚     â””â”€> Generate detailed report                                   â”‚
â”‚                                                                     â”‚
â”‚         Response: {                                                â”‚
â”‚           "timestamp": "2025-12-16T10:30:00Z",                     â”‚
â”‚           "validation_status": "healthy",                           â”‚
â”‚           "consistency_score": 0.98,                                â”‚
â”‚           "summary": {                                              â”‚
â”‚             "total_chunks": 10234,                                  â”‚
â”‚             "total_entities": 1353,                                 â”‚
â”‚             "total_relations": 2289                                 â”‚
â”‚           },                                                       â”‚
â”‚           "cross_reference_check": {                                â”‚
â”‚             "missing_in_qdrant": 0,                                 â”‚
â”‚             "payload_mismatches": 0,                                â”‚
â”‚             "status": "OK"                                          â”‚
â”‚           },                                                       â”‚
â”‚           "orphaned_check": {                                       â”‚
â”‚             "orphaned_entities": 0,                                 â”‚
â”‚             "orphaned_chunks": 0,                                   â”‚
â”‚             "status": "OK"                                          â”‚
â”‚           },                                                       â”‚
â”‚           "relation_integrity": {                                   â”‚
â”‚             "dangling_relations": 0,                                â”‚
â”‚             "invalid_weights": 0,                                   â”‚
â”‚             "invalid_types": 0,                                     â”‚
â”‚             "status": "OK"                                          â”‚
â”‚           },                                                       â”‚
â”‚           "recommendations": []                                     â”‚
â”‚         }                                                          â”‚
â”‚                                                                     â”‚
â”‚  7. Admin Dashboard Display                                         â”‚
â”‚     â””â”€> Show validation results in Admin UI                        â”‚
â”‚         - Consistency score: 0.98 (green indicator)                 â”‚
â”‚         - All checks: PASS                                          â”‚
â”‚         - Last validated: 2025-12-16 10:30 UTC                     â”‚
â”‚         - Action buttons:                                           â”‚
â”‚           * "Run Full Deduplication" (if score < 0.95)              â”‚
â”‚           * "Export Report" (JSON/CSV)                              â”‚
â”‚           * "Run Again" (manual trigger)                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~15s
- Data Collection: 3s (parallel queries)
- Chunk Presence: 4s (10K+ checks)
- Entity Mapping: 5s (1.3K+ checks)
- Relation Integrity: 2s (2.3K+ checks)
- Report Generation: 1s (aggregation)

Key Features (Sprint 49.6):
- Cross-reference consistency verification
- Orphaned entity/chunk detection
- Automatic consistency scoring (0-1)
- Detailed diagnostic report
- Actionable recommendations
```

---

### Scenario 8: Dynamic LLM & Relationship Type Discovery (Sprint 49.1-49.2)

**Admin Action:** Configure LLM models and graph relationship types dynamically without code changes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flow: Dynamic Discovery (LLM Models + Relationship Types)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. Dynamic LLM Model Discovery (Sprint 49.1)                       â”‚
â”‚     â””â”€> GET /api/v1/admin/ollama/models                            â”‚
â”‚                                                                     â”‚
â”‚         A. Query Ollama Available Models                            â”‚
â”‚            â””â”€> OllamaClient.list_models()                          â”‚
â”‚                HTTP GET http://localhost:11434/api/tags            â”‚
â”‚                Response: {                                         â”‚
â”‚                  "models": [                                       â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "llama3.2:8b",                         â”‚
â”‚                      "modified_at": "2025-12-15T...",              â”‚
â”‚                      "size": 4800000000,                            â”‚
â”‚                      "digest": "sha256:abc123..."                   â”‚
â”‚                    },                                              â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "bge-m3",  # Embedding model           â”‚
â”‚                      "modified_at": "2025-12-01T...",              â”‚
â”‚                      "size": 1600000000                             â”‚
â”‚                    },                                              â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "nemotron-mini",  # NEW               â”‚
â”‚                      "modified_at": "2025-12-14T...",              â”‚
â”‚                      "size": 900000000                              â”‚
â”‚                    },                                              â”‚
â”‚                    ...                                             â”‚
â”‚                  ]                                                 â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚         B. Filter Generation Models (exclude embeddings)            â”‚
â”‚            â””â”€> Filter by:                                          â”‚
â”‚                - Exclude: bge-m3 (embedding only)                   â”‚
â”‚                - Exclude: ms-marco-minilm (reranker only)           â”‚
â”‚                - Include: Anything else (generation models)         â”‚
â”‚                                                                     â”‚
â”‚                Filtered Models: [                                   â”‚
â”‚                  "llama3.2:8b",       # Current default             â”‚
â”‚                  "nemotron-mini",     # NEW (Sprint 49)             â”‚
â”‚                  "phi3",                                            â”‚
â”‚                  "mistral:7b",                                      â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                                                                     â”‚
â”‚         C. Response to Frontend                                     â”‚
â”‚            â””â”€> {                                                   â”‚
â”‚                  "generation_models": [                             â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "llama3.2:8b",                         â”‚
â”‚                      "size_gb": 4.8,                                â”‚
â”‚                      "type": "generation",                          â”‚
â”‚                      "is_current": true  # Currently selected       â”‚
â”‚                    },                                              â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "nemotron-mini",                       â”‚
â”‚                      "size_gb": 0.9,                                â”‚
â”‚                      "type": "generation",                          â”‚
â”‚                      "is_current": false                            â”‚
â”‚                    },                                              â”‚
â”‚                    ...                                             â”‚
â”‚                  ],                                                â”‚
â”‚                  "embedding_models": [                              â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "bge-m3",                              â”‚
â”‚                      "size_gb": 1.6,                                â”‚
â”‚                      "type": "embedding",                           â”‚
â”‚                      "is_current": true                             â”‚
â”‚                    }                                               â”‚
â”‚                  ]                                                 â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚  2. Dynamic Relationship Type Discovery (Sprint 49.2)               â”‚
â”‚     â””â”€> GET /api/v1/admin/graph/relationship-types                 â”‚
â”‚                                                                     â”‚
â”‚         A. Query Neo4j for All Relationship Types                   â”‚
â”‚            â””â”€> CALL db.relationshipTypes()                         â”‚
â”‚                Response: [                                         â”‚
â”‚                  "RELATES_TO",   # Semantic relationships            â”‚
â”‚                  "MENTIONED_IN", # Chunk references                 â”‚
â”‚                  "HAS_SECTION",  # Document structure               â”‚
â”‚                  "USES",         # Entity relationships              â”‚
â”‚                  "COMPONENT_OF",                                     â”‚
â”‚                  "IMPLEMENTS",                                       â”‚
â”‚                  ...                                               â”‚
â”‚                ]                                                   â”‚
â”‚                Total Types: 47                                      â”‚
â”‚                                                                     â”‚
â”‚         B. Compute Relationship Statistics                          â”‚
â”‚            â””â”€> For each relationship type:                         â”‚
â”‚                Neo4j Query:                                         â”‚
â”‚                MATCH ()-[r:RELATES_TO]->()                         â”‚
â”‚                RETURN count(r) as count,                            â”‚
â”‚                       min(r.weight) as min_weight,                  â”‚
â”‚                       max(r.weight) as max_weight,                  â”‚
â”‚                       avg(r.weight) as avg_weight                   â”‚
â”‚                                                                     â”‚
â”‚                Results: {                                          â”‚
â”‚                  "RELATES_TO": {                                    â”‚
â”‚                    "count": 2289,                                   â”‚
â”‚                    "min_weight": 0.65,                              â”‚
â”‚                    "max_weight": 0.99,                              â”‚
â”‚                    "avg_weight": 0.84                               â”‚
â”‚                  },                                                â”‚
â”‚                  "MENTIONED_IN": {                                  â”‚
â”‚                    "count": 3421,                                   â”‚
â”‚                    "min_weight": 1,                                 â”‚
â”‚                    "max_weight": 1,                                 â”‚
â”‚                    "avg_weight": 1.0                                â”‚
â”‚                  },                                                â”‚
â”‚                  ...                                               â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚         C. Response to Frontend                                     â”‚
â”‚            â””â”€> {                                                   â”‚
â”‚                  "relationship_types": [                            â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "RELATES_TO",                          â”‚
â”‚                      "count": 2289,                                 â”‚
â”‚                      "weight_range": [0.65, 0.99],                  â”‚
â”‚                      "avg_weight": 0.84,                            â”‚
â”‚                      "color": "#3B82F6",  # Blue (hardcoded)         â”‚
â”‚                      "category": "semantic"                         â”‚
â”‚                    },                                              â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "MENTIONED_IN",                        â”‚
â”‚                      "count": 3421,                                 â”‚
â”‚                      "weight_range": [1.0, 1.0],                    â”‚
â”‚                      "avg_weight": 1.0,                             â”‚
â”‚                      "color": "#9CA3AF",  # Gray                     â”‚
â”‚                      "category": "mention"                          â”‚
â”‚                    },                                              â”‚
â”‚                    {                                               â”‚
â”‚                      "name": "HAS_SECTION",                         â”‚
â”‚                      "count": 934,                                  â”‚
â”‚                      "weight_range": [0.9, 1.0],                    â”‚
â”‚                      "avg_weight": 0.98,                            â”‚
â”‚                      "color": "#10B981",  # Green                    â”‚
â”‚                      "category": "structure"                        â”‚
â”‚                    },                                              â”‚
â”‚                    ...                                             â”‚
â”‚                  ]                                                 â”‚
â”‚                }                                                   â”‚
â”‚                                                                     â”‚
â”‚  3. Admin UI Update                                                 â”‚
â”‚     â””â”€> Populate dropdowns/selects dynamically                     â”‚
â”‚                                                                     â”‚
â”‚         A. LLM Model Selector (Settings Page)                       â”‚
â”‚            â””â”€> <select>                                            â”‚
â”‚                  <option value="llama3.2:8b">                       â”‚
â”‚                    llama3.2:8b (4.8 GB) - Current                   â”‚
â”‚                  </option>                                         â”‚
â”‚                  <option value="nemotron-mini">                     â”‚
â”‚                    nemotron-mini (0.9 GB)                           â”‚
â”‚                  </option>                                         â”‚
â”‚                  ...                                               â”‚
â”‚                </select>                                           â”‚
â”‚                                                                     â”‚
â”‚         B. Relationship Type Multi-Select (Graph Filter)            â”‚
â”‚            â””â”€> <MultiSelect>                                       â”‚
â”‚                  checked: ["RELATES_TO", "MENTIONED_IN", ...]       â”‚
â”‚                  options: [                                        â”‚
â”‚                    "RELATES_TO" (2289 relations),                   â”‚
â”‚                    "MENTIONED_IN" (3421 relations),                 â”‚
â”‚                    "HAS_SECTION" (934 relations),                   â”‚
â”‚                    ...                                             â”‚
â”‚                  ]                                                 â”‚
â”‚                </MultiSelect>                                      â”‚
â”‚                                                                     â”‚
â”‚  4. User Interaction                                                â”‚
â”‚     â””â”€> Admin changes LLM model in dropdown                        â”‚
â”‚         POST /api/v1/admin/settings/llm-model                      â”‚
â”‚         Body: {"model": "nemotron-mini"}                            â”‚
â”‚                                                                     â”‚
â”‚         Response: {"status": "success", "model": "nemotron-mini"}   â”‚
â”‚         Config saved to environment/database                        â”‚
â”‚         Next API call uses nemotron-mini                            â”‚
â”‚                                                                     â”‚
â”‚  5. Benefits of Dynamic Discovery                                   â”‚
â”‚     âœ“ No code changes needed to add/remove LLM models               â”‚
â”‚     âœ“ Relationship types discovered automatically from graph        â”‚
â”‚     âœ“ Users see accurate statistics (count, weights)                â”‚
â”‚     âœ“ UI stays current with Neo4j schema evolution                  â”‚
â”‚     âœ“ New models available immediately after Ollama pull            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total Latency: ~500ms
- Ollama Query: 150ms
- Neo4j Relationship Query: 300ms
- Filtering & Aggregation: 50ms

Key Features (Sprint 49.1-49.2):
- Zero hardcoded LLM model list
- Zero hardcoded relationship types
- Real-time discovery from running services
- Automatic filtering of embedding models
- Statistical metadata for each type
```

---

## ðŸ”§ COMPONENT DETAILS

### FastAPI Endpoints

| Endpoint | Method | Purpose | Request | Response |
|----------|--------|---------|---------|----------|
| `/health` | GET | Health check | - | `{"status": "healthy"}` |
| `/ready` | GET | Readiness check | - | `{"ready": true}` |
| `/live` | GET | Liveness check | - | `{"alive": true}` |
| `/api/v1/chat` | POST | Chat query | `ChatRequest` | `ChatResponse` |
| `/api/v1/documents/upload` | POST | Document upload | `multipart/form-data` | `IngestionResponse` |
| `/api/v1/search` | POST | Raw search (no LLM) | `SearchRequest` | `SearchResponse` |
| `/api/v1/graph/export/json` | GET | Export graph as JSON | - | `GraphJSON` |
| `/api/v1/graph/export/graphml` | GET | Export as GraphML | - | `GraphML` |
| `/stats` | GET | System statistics | - | `SystemStats` |
| `/api/v1/admin/deduplicate-graph` | POST | Deduplicate entities + relations (Sprint 49) | `{"confirm": true}` | SSE stream with progress |
| `/api/v1/admin/validate-consistency` | GET | Validate cross-index consistency (Sprint 49.6) | `?full=true` | `ConsistencyReport` |
| `/api/v1/admin/ollama/models` | GET | List available LLM models (Sprint 49.1) | - | `{"generation_models": [...], "embedding_models": [...]}` |
| `/api/v1/admin/graph/relationship-types` | GET | List all relationship types with stats (Sprint 49.2) | - | `{"relationship_types": [...]}` |

### LangGraph State Schema

```python
from pydantic import BaseModel
from typing import List, Dict, Optional

class AgentState(BaseModel):
    """Centralized state for LangGraph agents."""

    # Input
    query: str
    session_id: str
    rag_mode: str  # "vector" | "graph" | "hybrid"

    # Router outputs
    query_type: Optional[str] = None  # "SIMPLE" | "COMPOUND" | "MULTI_HOP" | "MEMORY_QUERY"
    selected_agents: List[str] = []  # ["vector", "graph", "memory"]

    # Agent outputs
    vector_results: List[Dict] = []
    graph_results: List[Dict] = []
    memory_results: List[Dict] = []

    # Aggregation
    final_context: str = ""
    final_answer: str = ""
    sources: List[Dict] = []

    # Metadata
    metadata: Dict = {}
    error: Optional[str] = None
```

### Redis Data Structures

```python
# Session State (LangGraph Checkpointer)
KEY: "session:{session_id}:state"
VALUE: <pickled AgentState>
TTL: 86400 seconds (24 hours)

# Recent Messages (Short-Term Memory)
KEY: "session:{session_id}:messages"
VALUE: [
    {
        "role": "user",
        "content": "What is RAG?",
        "timestamp": "2025-10-22T10:15:00Z"
    },
    {
        "role": "assistant",
        "content": "RAG is...",
        "timestamp": "2025-10-22T10:15:02Z"
    }
]
TTL: 3600 seconds (1 hour)

# Embedding Cache (LRU)
KEY: "embedding:{sha256(text)}"
VALUE: [0.123, -0.456, ..., 0.789]  # 1024d vector (BGE-M3, Sprint 16)
TTL: 604800 seconds (7 days)
```

### Qdrant Collections

```python
# Vector Collection
collection_name = "aegis-rag-documents"
vector_size = 1024  # bge-m3 (Sprint 16)
distance = "Cosine"

# Point Structure
{
    "id": "doc1_chunk1",
    "vector": [0.123, -0.456, ...],  # 1024 dimensions (BGE-M3)
    "payload": {
        "text": "RAG is Retrieval-Augmented Generation...",
        "source": "rag_overview.md",
        "chunk_id": 1,
        "doc_hash": "sha256...",
        "metadata": {
            "document_type": "markdown",
            "date_added": "2025-10-22",
            "tags": ["rag", "llm", "retrieval"]
        }
    }
}

# Conversation History Collection
collection_name = "conversation-history"
vector_size = 1024  # bge-m3 (Sprint 16)

# Point Structure
{
    "id": "conv1",
    "vector": [0.234, -0.567, ...],  # 1024 dimensions (BGE-M3)
    "payload": {
        "session_id": "abc123",
        "summary": "Discussed RAG definition and use cases",
        "timestamp": "2025-10-22T10:15:00Z",
        "turns": 2
    }
}
```

### Sprint 49 Component Details

#### EntityDeduplicator (Sprint 49.9)

**Purpose:** Identify and merge duplicate entities based on semantic similarity

**Interface:**
```python
class EntityDeduplicator:
    async def deduplicate(
        self,
        entities: List[Entity],
        similarity_threshold: float = 0.85
    ) -> DeduplicationResult:
        """
        Deduplicate entities using BGE-M3 embeddings.

        Returns: {
            "canonical_map": Dict[str, str],  # variant â†’ canonical
            "duplicates_found": int,
            "merged_entities": int
        }
        """
```

**Data Flow:**
1. Load all entities from Neo4j
2. Batch embed entity names using BGE-M3 (1024-dim)
3. Compute pairwise cosine similarities (vectorized)
4. Cluster entities with similarity >= 0.85
5. Select canonical entity (most frequent/recent)
6. Return canonical mapping for Phase 4

---

#### SemanticRelationDeduplicator (Sprint 49.7)

**Purpose:** Identify and normalize duplicate relationship types

**Interface:**
```python
class SemanticRelationDeduplicator:
    async def deduplicate_types(
        self,
        relation_types: List[str],
        clustering_threshold: float = 0.88
    ) -> TypeDeduplicationResult:
        """
        Deduplicate relation types using hierarchical clustering.

        Returns: {
            "type_synonym_map": Dict[str, str],  # variant â†’ canonical
            "synonyms_found": int,
            "clusters": List[List[str]]
        }
        """
```

**Data Flow:**
1. Extract all unique relation types from Neo4j
2. Batch embed relation type names using BGE-M3
3. Perform hierarchical clustering (Ward linkage)
4. Group types with similarity >= 0.88
5. Store mapping in Redis for (Sprint 49.8) overrides
6. Return canonical mapping for Phase 4

---

#### RelationNormalizer (Sprint 49.3)

**Purpose:** Apply deduplication maps to normalize graph

**Interface:**
```python
class RelationNormalizer:
    async def normalize_relations(
        self,
        entity_map: Dict[str, str],  # variant â†’ canonical
        type_map: Dict[str, str],    # variant_type â†’ canonical_type
        handle_symmetry: bool = True
    ) -> NormalizationResult:
        """
        Normalize relations using canonical entity and type mappings.

        Returns: {
            "entities_remapped": int,
            "types_normalized": int,
            "symmetric_resolved": int,
            "relations_merged": int
        }
        """
```

**Data Flow:**
1. For each relation in Neo4j:
   - Remap source entity name using entity_map
   - Remap target entity name using entity_map
   - Normalize relation type using type_map
2. Detect bidirectional relations (e1â†’e2 and e2â†’e1)
3. Keep only one direction, merge weights
4. Group by (source, target, type), deduplicate
5. Execute atomic transaction to update Neo4j

---

#### IndexConsistencyValidator (Sprint 49.6)

**Purpose:** Validate cross-index consistency between Qdrant, Neo4j, and chunks

**Interface:**
```python
class IndexConsistencyValidator:
    async def validate_consistency(
        self,
        full_check: bool = False
    ) -> ConsistencyReport:
        """
        Validate index consistency across all stores.

        Returns: {
            "consistency_score": float,  # 0-1
            "total_chunks": int,
            "total_entities": int,
            "total_relations": int,
            "issues": {
                "orphaned_entities": List[str],
                "orphaned_chunks": List[str],
                "dangling_relations": List[Tuple[str, str, str]],
                "missing_in_qdrant": List[str]
            },
            "status": "healthy" | "warning" | "error"
        }
        """
```

**Data Flow:**
1. Load all chunks from Qdrant (chunk_id, text, source)
2. Load all entities from Neo4j (entity_id, name)
3. Load all MENTIONED_IN links (entityâ†’chunk)
4. Verify chunk presence: for each entity link, check chunk exists in Qdrant
5. Detect orphaned entities: entities with no MENTIONED_IN links
6. Verify relation integrity: all referenced entities exist, weights valid
7. Generate consistency score: (total_checks - failures) / total_checks
8. Return detailed report with recommendations

---

### Neo4j Graph Schema

```cypher
// Entity Node
(:Entity {
    name: "Transformer",
    type: "MODEL",
    source: "transformer_paper.pdf",
    first_seen: "2025-10-22T10:15:00Z",
    confidence: 0.95
})

// Relationship Types (Sprint 34)
// 1. RELATES_TO: Semantic relationships (blue #3B82F6)
(:Entity {name: "Transformer"})-[:RELATES_TO {weight: 0.92, extraction_method: "llm"}]->(:Entity {name: "Attention Mechanism"})

// 2. MENTIONED_IN: Chunk references (gray #9CA3AF)
(:Entity {name: "Transformer"})-[:MENTIONED_IN {frequency: 15}]->(:Chunk {id: "chunk_abc123"})

// 3. HAS_SECTION: Document structure (green #10B981)
(:Document {id: "doc_123"})-[:HAS_SECTION]->(:Section {title: "Introduction", page: 1})

// Community Node
(:Community {
    id: "community1",
    topic: "Transformer Architecture",
    summary: "Models and techniques for transformer-based architectures",
    size: 15,
    created: "2025-10-22T10:15:00Z"
})

// Membership
(:Entity {name: "Transformer"})-[:BELONGS_TO]->(:Community {id: "community1"})

// Section Node (Sprint 34)
(:Section {
    id: "section_123",
    title: "Load Balancing",
    document_id: "doc_456",
    page: 2,
    level: 1  # Heading level
})
(:Section {id: "section_123"})-[:PARENT]->(:Document {id: "doc_456"})

// Graphiti Episodic Memory (via Graphiti SDK)
(:Episode {
    session_id: "abc123",
    valid_from: "2025-10-22T10:15:00Z",
    valid_to: "9999-12-31T23:59:59Z",  # Still valid
    transaction_time: "2025-10-22T10:15:00Z"
})-[:CONTAINS]->(:Fact {
    text: "User asked about RAG definition",
    confidence: 0.9
})
```

---

## ðŸ“Š API CONTRACTS

### ChatRequest (POST /api/v1/chat)

```json
{
  "query": "What is RAG?",
  "session_id": "abc123",  // Optional, generated if missing
  "rag_mode": "hybrid",    // "vector" | "graph" | "hybrid"
  "options": {
    "top_k": 5,
    "temperature": 0.7,
    "model": "llama3.2:8b"
  }
}
```

### ChatResponse

```json
{
  "answer": "RAG (Retrieval-Augmented Generation) is a technique...",
  "sources": [
    {
      "file": "rag_overview.md",
      "chunk_id": 1,
      "score": 0.95,
      "text": "RAG is Retrieval-Augmented Generation..."
    },
    {
      "file": "llama_index.md",
      "chunk_id": 3,
      "score": 0.88,
      "text": "LlamaIndex implements RAG patterns..."
    }
  ],
  "session_id": "abc123",
  "metadata": {
    "tokens": 150,
    "latency_ms": 450,
    "rag_mode": "hybrid",
    "agents_used": ["router", "vector", "aggregator"],
    "model": "llama3.2:8b"
  }
}
```

### IngestionResponse (POST /api/v1/documents/upload)

```json
{
  "status": "success",
  "filename": "transformer_paper.pdf",
  "chunks_created": 45,
  "entities_extracted": 87,
  "relationships_created": 124,
  "indexing_time_ms": 10000,
  "doc_hash": "sha256:abc123...",
  "collections_updated": ["aegis-rag-documents", "conversation-history"]
}
```

---

## ðŸŽ¯ EMBEDDING MODEL CONSOLIDATION (Sprint 49)

### Overview

Sprint 49 consolidates all embedding tasks to use BGE-M3 (1024-dim), removing dependency on sentence-transformers for entity deduplication and relation type clustering.

**Before Sprint 49:**
- Query embeddings: BGE-M3 (Ollama)
- Document chunk embeddings: BGE-M3 (Ollama)
- Entity deduplication: sentence-transformers/all-MiniLM-L6-v2
- Reranking: sentence-transformers/ms-marco-MiniLM (removed in Sprint 48)

**After Sprint 49:**
- Query embeddings: BGE-M3 (Ollama)
- Document chunk embeddings: BGE-M3 (Ollama)
- Entity deduplication: BGE-M3 (Ollama) - NEW
- Relation type clustering: BGE-M3 (Ollama) - NEW

### Unified Embedding Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UnifiedEmbeddingService                â”‚
â”‚  (All embedding tasks route here)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  embed(text: str) â†’ [1024d vector]     â”‚
â”‚  embed_batch(texts: List[str])          â”‚
â”‚                 â†’ List[[1024d vector]]  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ LRU Cache (SHA-256 hash key)    â”‚   â”‚
â”‚  â”‚ - Query embedding hits          â”‚   â”‚
â”‚  â”‚ - Entity name embedding hits    â”‚   â”‚
â”‚  â”‚ - Relation type embedding hits  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚ cache miss                  â”‚
â”‚           â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Ollama API (localhost:11434)    â”‚   â”‚
â”‚  â”‚ POST /api/embeddings            â”‚   â”‚
â”‚  â”‚ - model: "bge-m3"               â”‚   â”‚
â”‚  â”‚ - inputs: batch of texts        â”‚   â”‚
â”‚  â”‚ Response: List[1024d vector]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                             â”‚
â”‚           â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Cache Store                     â”‚   â”‚
â”‚  â”‚ Redis key: embedding:{hash}     â”‚   â”‚
â”‚  â”‚ TTL: 7 days                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Usage by Component

#### 1. Query Embedding (existing)
```
User Query â†’ UnifiedEmbeddingService.embed()
  â†’ Cache: embedding:{hash("What is RAG?")}
  â†’ Hit? Return cached vector
  â†’ Miss? Call Ollama â†’ Cache â†’ Return
  â†’ Use vector for Qdrant search
  â†’ Latency: 50ms (miss), 5ms (hit)
```

#### 2. Document Chunk Embedding (existing)
```
Document Chunk â†’ UnifiedEmbeddingService.embed_batch()
  â†’ Batch of 32 chunks
  â†’ Call Ollama once (not 32 times)
  â†’ Cache each result
  â†’ Use vectors for Qdrant insert
  â†’ Latency: ~2s for 45 chunks
```

#### 3. Entity Name Embedding (NEW - Sprint 49.9)
```
Entity Deduplicator:
  Load all entities: [
    "Transformer",
    "Transformers",
    "TransformerModel",
    ...
  ]
  â”‚
  â”œâ”€ Check cache for each entity name
  â”œâ”€ Batch embed cache misses
  â”œâ”€ Store cache hits + new embeddings
  â”‚
  â–¼ Embeddings: [[0.123, ...], [0.125, ...], ...]
  â”‚
  â”œâ”€ Compute pairwise cosine similarities
  â”œâ”€ Cluster at similarity >= 0.85
  â”œâ”€ Create canonical mapping
  â”‚
  â–¼ Dedup results
```

#### 4. Relation Type Embedding (NEW - Sprint 49.7)
```
SemanticRelationDeduplicator:
  Load all relation types: [
    "USES",
    "uses",
    "RELATED_TO",
    "related-to",
    ...
  ]
  â”‚
  â”œâ”€ Check cache for each type
  â”œâ”€ Batch embed cache misses
  â”œâ”€ Store cache hits + new embeddings
  â”‚
  â–¼ Embeddings: [[0.234, ...], [0.235, ...], ...]
  â”‚
  â”œâ”€ Perform hierarchical clustering (Ward)
  â”œâ”€ Group at similarity >= 0.88
  â”œâ”€ Create type synonym mapping
  â”‚
  â–¼ Type synonym results
```

### Performance Characteristics

| Task | Items | Batch Size | Latency | Bottleneck |
|------|-------|-----------|---------|-----------|
| Query Embedding | 1 | 1 | 50ms | Ollama |
| Chunk Embedding | 10K | 32 | 2s | Ollama (10K * 25ms) |
| Entity Embedding | 1.5K | 32 | 3s | Ollama (1.5K * 2ms) |
| Entity Similarity | 1.5K | N/A | 2s | Vectorized cosine |
| Type Embedding | 47 | 32 | 200ms | Ollama |
| Type Clustering | 47 | N/A | 1s | Hierarchical clustering |

### Cache Hit/Miss Rates

**Query Embeddings:**
- Cache hit rate: ~60% (same questions asked multiple times)
- Miss rate: ~40% (new queries)
- Impact: 60% of queries save 45ms

**Entity Name Embeddings:**
- Cache hit rate: ~20% (incremental ingestion)
- Miss rate: ~80% (new entities from documents)
- Impact: Mostly miss, but amortized cost via batch embedding

**Relation Type Embeddings:**
- Cache hit rate: ~95% (stable set of types)
- Miss rate: ~5% (occasional new relation types from LLM)
- Impact: After first dedup, subsequent runs cache-hit for all types

### Removed Dependencies

**sentence-transformers/all-MiniLM-L6-v2**
- Used for: Entity deduplication (Sprint 48)
- Size: 80MB
- Latency: 30ms per entity
- Reason for removal: BGE-M3 is superior (multilingual, 1024-dim)
- Migration: Replace with BGE-M3 batch embedding in EntityDeduplicator

**sentence-transformers/ms-marco-MiniLM**
- Used for: Reranking (Sprint 48)
- Size: 90MB
- Status: Already removed in Sprint 48
- Reason: LLM-based generation provides better quality

### Benefits of Consolidation

1. **Single embedding model:** BGE-M3 (multilingual, 1024-dim, cross-encoder)
2. **Reduced memory footprint:** No need to load multiple transformer models
3. **Consistent embeddings:** All text embedded the same way (semantic consistency)
4. **Better performance:** BGE-M3 > sentence-transformers for multilingual + dense retrieval
5. **Simpler operations:** Manage one model instead of multiple
6. **Cost reduction:** Single Ollama model loaded, not multiple models

---

## ðŸŽ¯ KEY TAKEAWAYS

### Critical Data Paths
1. **User Query â†’ LLM Response:** ~400ms (simple), ~800ms (graph), ~350ms (memory)
2. **Document Upload â†’ Indexed:** ~10s (parallel), ~22s (sequential)
3. **Embedding Generation:** ~50ms (cache miss), ~5ms (cache hit)
4. **Redis State Persistence:** <10ms
5. **Neo4j Graph Query:** ~200ms (low-level), ~500ms (high-level)

### Performance Bottlenecks
1. **Entity Extraction:** Slowest part of ingestion (~8s for 45 chunks)
2. **Community Detection:** ~2s per run
3. **LLM Generation:** ~250ms (GPU), ~3.5s (CPU)

### Optimization Strategies
1. **Parallel Indexing:** 2.25x speedup (Sprint 11)
2. **LRU Embedding Cache:** 60% hit rate, ~90% latency reduction
3. **GPU Acceleration:** 15-20x LLM speedup (Sprint 11)
4. **Batch Embedding:** Process 10 chunks at once

---

## ðŸš€ PLANNED: Graph Visualization Frontend (Sprint 29)

**Status:** ðŸ“‹ PLANNED (36 SP, 7-9 days estimated)
**Sprint:** Sprint 29
**Plan Document:** [SPRINT_29_PLAN.md](sprints/SPRINT_29_PLAN.md)

### Overview

Sprint 29 will deliver comprehensive graph visualization frontend for AegisRAG's knowledge graph, enabling end users to explore query results visually and admins to analyze the entire knowledge graph with community detection.

**Technology Stack:**
- **Library:** `react-force-graph` (2D mode with WebGL)
- **API:** Existing Graph Viz API from Sprint 12 (`/api/v1/graph/viz/*`)
- **Styling:** Tailwind CSS + Lucide Icons

### Planned Features (7 Use Cases)

#### 1. Query Result Graph (End User)
**Feature 29.2 (3 SP):** View entities and relationships from query results
- "View Graph" button in StreamingAnswer component
- Modal with interactive graph of entities from retrieved context
- Highlights entities mentioned in answer
- Example: Query "How are transformers related to attention?" â†’ Shows Transformer â†’ USES â†’ Attention Mechanism

#### 2. Admin Graph Analytics
**Feature 29.3 (5 SP):** Admin-only page at `/admin/graph`
- Full knowledge graph visualization (up to 500 nodes)
- Advanced filters: Entity types, minimum degree, max nodes
- Community highlighting
- Graph statistics: Node count, edge count, avg degree

#### 3. Knowledge Graph Dashboard
**Feature 29.4 (5 SP):** Graph metrics and insights
- Quick stats: Total nodes, edges, communities, avg degree
- Entity type distribution (pie chart)
- Graph growth timeline (line chart, last 30 days)
- Top 10 communities by size
- Health metrics: Orphaned nodes, disconnected components

#### 4. Graph Explorer with Search
**Feature 29.5 (5 SP):** Interactive navigation tools
- Node search: Type entity name â†’ graph centers on node with zoom
- Filter by entity type: Show only PERSON, ORGANIZATION, etc.
- Community highlighting: Select community â†’ highlight all members
- Degree filter: Show only highly connected nodes

#### 5. Pan, Zoom, Node Interactions
**Feature 29.1 (5 SP):** Base graph viewer component
- Pan: Click + drag background
- Zoom: Mouse wheel (zoom in/out)
- Node hover: Tooltip with entity name, type, degree
- Node click: Highlight node + connected edges + open details panel
- Performance: 60 FPS with 100+ nodes (WebGL rendering)

#### 6. Embedding-based Document Search
**Feature 29.6 (8 SP):** Find documents from graph nodes
- Click node â†’ Side panel shows "Related Documents"
- Backend: Embed entity name (BGE-M3) â†’ Qdrant vector search
- Display: Top 10 documents with similarity scores
- Click document â†’ Opens document preview
- API: `POST /api/v1/graph/viz/node-documents`

#### 7. Community Document Browser
**Feature 29.7 (5 SP):** Browse documents by community
- Select community â†’ "View Community Documents" button
- Modal shows all documents mentioning entities from community
- Documents grouped by relevance
- Highlights mentioned entities in excerpts
- API: `GET /api/v1/graph/viz/communities/{id}/documents`

### Component Architecture

```
frontend/src/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ GraphVisualizationPage.tsx        # Main graph page
â”‚   â””â”€â”€ admin/
â”‚       â””â”€â”€ GraphAnalyticsPage.tsx        # Admin-only page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ GraphViewer.tsx               # Core 2D graph (react-force-graph)
â”‚   â”‚   â”œâ”€â”€ GraphControls.tsx             # Pan/Zoom/Reset controls
â”‚   â”‚   â”œâ”€â”€ GraphSearch.tsx               # Node search
â”‚   â”‚   â”œâ”€â”€ CommunityHighlight.tsx        # Community highlighting
â”‚   â”‚   â”œâ”€â”€ NodeDetailsPanel.tsx          # Selected node info + docs
â”‚   â”‚   â”œâ”€â”€ CommunityDocuments.tsx        # Community â†’ Documents
â”‚   â”‚   â”œâ”€â”€ GraphFilters.tsx              # Entity type, degree filters
â”‚   â”‚   â””â”€â”€ GraphExportButton.tsx         # Export JSON/GraphML/Cytoscape
â”‚   â””â”€â”€ dashboard/
â”‚       â”œâ”€â”€ KnowledgeGraphDashboard.tsx   # Statistics dashboard
â”‚       â”œâ”€â”€ GraphStatistics.tsx           # Node/Edge/Community counts
â”‚       â””â”€â”€ TopCommunities.tsx            # Top 10 communities
â”œâ”€â”€ api/
â”‚   â””â”€â”€ graphViz.ts                       # API client for graph viz
â””â”€â”€ hooks/
    â”œâ”€â”€ useGraphData.ts                   # Fetch graph data
    â”œâ”€â”€ useGraphSearch.ts                 # Node search logic
    â””â”€â”€ useDocumentsByNode.ts             # Embedding-based doc search
```

### API Endpoints

**Existing (Sprint 12):**
- âœ… `POST /api/v1/graph/viz/export` - Export graph (JSON/GraphML/Cytoscape)
- âœ… `GET /api/v1/graph/viz/export/formats` - Supported formats
- âœ… `POST /api/v1/graph/viz/filter` - Filter by entity types/degree
- âœ… `POST /api/v1/graph/viz/communities/highlight` - Highlight communities

**New (Sprint 29):**
- âŒ `POST /api/v1/graph/viz/query-subgraph` - Get entities from query results (Feature 29.2)
- âŒ `GET /api/v1/graph/viz/statistics` - Graph statistics (Feature 29.4)
- âŒ `POST /api/v1/graph/viz/node-documents` - Documents by entity (Feature 29.6)
- âŒ `GET /api/v1/graph/viz/communities/{id}/documents` - Community documents (Feature 29.7)

### Performance Targets

- **Graph Rendering:** <1s for 100 nodes, <3s for 500 nodes
- **Search Latency:** <200ms for node search
- **Document Lookup:** <500ms for embedding-based search
- **Frame Rate:** 60 FPS with pan/zoom (WebGL rendering)

### Success Criteria

- [ ] All 7 features implemented and tested
- [ ] GraphViewer renders 100+ nodes at 60 FPS
- [ ] End users can view query result graphs
- [ ] Admins can explore entire knowledge graph
- [ ] Document search from graph nodes works
- [ ] Community document browser functional
- [ ] Unit test coverage >80%
- [ ] E2E tests pass for all user flows
- [ ] Documentation updated (API docs, user guide)

---

**Last Updated:** 2025-12-16 (Sprint 49 - Knowledge Graph Deduplication)
**Status:** Active Development

**Architecture Changes Since Sprint 16:**
- **Sprint 21-22:** LangGraph ingestion pipeline with Docling CUDA + Format Router
- **Sprint 23:** AegisLLMProxy multi-cloud LLM routing (ADR-033)
- **Sprint 25:** Complete migration to AegisLLMProxy (Feature 25.10)
- **Sprint 28:** Frontend UX enhancements (Perplexity-style interface)
- **Sprint 34:** Knowledge graph enhancement with RELATES_TO relationships and edge visualization
- **Sprint 49:** Knowledge graph deduplication (entity + relation dedup), embedding consolidation, index validation

**Current Architecture (Sprint 49):**
- **Embeddings:** BGE-M3 (1024-dim, Sprint 16) - Unified for all embedding tasks (query, chunks, dedup, relations)
- **LLM Routing:** AegisLLMProxy (Local Ollama â†’ Alibaba Cloud â†’ OpenAI)
- **Search Strategy:** Hybrid (Vector BGE-M3 + BM25 Keyword + RRF Fusion)
- **Graph Relationships:** RELATES_TO (semantic), MENTIONED_IN (chunk refs + source_chunk_id), HAS_SECTION (document structure)
- **Entity Deduplication:** BGE-M3 embeddings + cosine similarity (0.85 threshold) - Sprint 49.9
- **Relation Deduplication:** Hierarchical clustering (0.88 threshold) + type synonym mapping - Sprint 49.7
- **Relation Normalization:** Entity remapping + symmetric handling + dedup by (source, target, type)
- **Index Validation:** Cross-reference consistency check + orphaned entity/chunk detection - Sprint 49.6
- **Edge Visualization:** Color-coded by type (Blue: RELATES_TO, Gray: MENTIONED_IN, Green: HAS_SECTION)
- **Ingestion:** LangGraph pipeline (Docling primary, LlamaIndex fallback)
- **Document Formats:** 30+ formats (FormatRouter Sprint 22.3)
- **Relation Extraction:** Pure LLM via AegisLLMProxy (Alibaba Cloud Qwen3-32B)
- **Dynamic Discovery:** LLM model list + relationship types from Neo4j (Sprint 49.1-49.2)

**Next:** Sprint 50 (Continued graph optimization and scalability improvements)
