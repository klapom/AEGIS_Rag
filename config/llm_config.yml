# LLM Proxy Configuration
# Sprint 23 (Feature 23.4 - Mozilla ANY-LLM Integration)
# Related ADR: ADR-033

# Provider configuration
providers:
  local_ollama:
    base_url: "${OLLAMA_BASE_URL:-http://localhost:11434}"
    timeout: 60
    models:
      - hf.co/MaziyarPanahi/gemma-3-4b-it-GGUF:Q4_K_M  # Default extraction/generation model
      - bge-m3               # Embeddings (always local)
      - llava:7b-v1.6-mistral-q2_K  # Vision model

  alibaba_cloud:
    base_url: "${ALIBABA_CLOUD_BASE_URL:-https://dashscope-intl.aliyuncs.com/compatible-mode/v1}"
    api_key: "${ALIBABA_CLOUD_API_KEY:-}"  # Optional - leave empty if not using
    timeout: 120
    models:
      - qwen-turbo          # Fast and cost-effective
      - qwen-plus           # High quality
      - qwen-max            # Best quality (largest model)
      - qwen3-vl-30b-a3b-instruct  # Vision language model PRIMARY (cheaper output tokens)
      - qwen3-vl-30b-a3b-thinking  # Vision language model FALLBACK (on 403 errors)

  openai:
    api_key: "${OPENAI_API_KEY:-}"  # Optional - leave empty if not using
    organization: "${OPENAI_ORGANIZATION:-}"
    timeout: 60
    models:
      - gpt-4o       # Best quality (critical tasks)
      - gpt-4o-mini  # Cost-effective for testing
      - gpt-4        # Alternative high-quality model

# Budget management (monthly limits in USD)
budgets:
  monthly_limits:
    alibaba_cloud: 120.0  # $120/month (60% of total budget)
    openai: 80.0         # $80/month (40% of total budget)
  alert_threshold: 0.8   # Alert at 80% budget utilization
  reset_day: 1           # Reset on 1st of each month

# Routing configuration
# Sprint 33: Cloud-First Strategy for Performance Testing
# Set prefer_cloud: true to route extraction/generation to Alibaba Cloud Qwen
routing:
  default_provider: local_ollama
  prefer_cloud: true  # NEW: Route extraction/generation to cloud when true
  quality_critical_provider: openai
  batch_processing_provider: alibaba_cloud

  # Data classification overrides (GDPR/HIPAA compliance)
  # These classifications ALWAYS route to local (non-negotiable)
  data_classification_overrides:
    pii: local_ollama         # Personal Identifiable Information (GDPR)
    hipaa: local_ollama       # Protected Health Information (HIPAA)
    confidential: local_ollama  # Business secrets

  # Task type overrides
  task_type_overrides:
    embedding: local_ollama  # BGE-M3 excellent locally, no cloud benefit

  # Quality thresholds for provider selection
  quality_thresholds:
    openai_required:
      quality: critical
      complexity: high
    alibaba_cloud_preferred:
      quality: high
      complexity: medium

# Model selection per provider (defaults)
model_defaults:
  local_ollama:
    extraction: hf.co/MaziyarPanahi/gemma-3-4b-it-GGUF:Q4_K_M
    generation: hf.co/MaziyarPanahi/gemma-3-4b-it-GGUF:Q4_K_M
    embedding: bge-m3
  alibaba_cloud:
    extraction: qwen3-32b      # High quality extraction (32B params)
    generation: qwen3-32b      # High quality generation (32B params)
    vision: qwen3-vl-30b-a3b-instruct  # Vision language model PRIMARY (cheaper output)
  openai:
    extraction: gpt-4o
    generation: gpt-4o
    code_generation: gpt-4o
    research: gpt-4o

# Fallback chain (if primary provider fails)
fallback:
  enabled: true
  chain:
    - openai         # Try OpenAI first (if selected)
    - alibaba_cloud  # Fallback to Alibaba Cloud (Qwen)
    - local_ollama   # Always succeeds (local)
  max_retries: 3
  retry_delay_seconds: 2

# Monitoring & observability
monitoring:
  enable_metrics: true  # Prometheus metrics
  enable_tracing: true  # LangSmith tracing
  log_routing_decisions: true  # Log why each provider was chosen
  log_costs: true  # Log per-request costs
