[tool.poetry]
name = "aegis-rag"
version = "0.1.0"
description = "Agentic Enterprise Graph Intelligence System - Production-ready RAG with Multi-Agent Orchestration"
authors = ["AEGIS RAG Team <team@aegis-rag.com>"]
readme = "README.md"
license = "MIT"
homepage = "https://github.com/aegis-rag/aegis-rag"
repository = "https://github.com/aegis-rag/aegis-rag"
documentation = "https://docs.aegis-rag.com"
keywords = ["rag", "llm", "agents", "vector-search"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]
packages = [{include = "src"}]

# ============================================================================
# CORE DEPENDENCIES (ALWAYS INSTALLED)
# ============================================================================
[tool.poetry.dependencies]
# Core Python
python = ">=3.11,<3.13"  # Limited by graspologic dependency (optional group)

# Web Framework (Sprint 2: REST API)
fastapi = "^0.115.0"
uvicorn = {extras = ["standard"], version = "^0.30.0"}
pydantic = "^2.9.0"
pydantic-settings = "^2.5.0"

# Vector Database (Sprint 2: Qdrant)
qdrant-client = "~1.11.0"  # Pin to 1.11.x (compatible with Qdrant server v1.11.0)

# LLM Provider (Sprint 2: Ollama)
ollama = ">=0.6.0,<1.0.0"  # Updated to >=0.6.0 for langchain-ollama 1.0.0 compatibility

# Multi-Cloud LLM Abstraction (Sprint 23: Mozilla ANY-LLM)
any-llm-sdk = {extras = ["openai", "ollama"], version = "~1.2.0"}  # Multi-provider LLM abstraction (ADR-033)

# Hybrid Search (Sprint 2: BM25)
rank-bm25 = "^0.2.2"

# Utilities (Core)
python-dotenv = "^1.0.0"
tenacity = ">=8.1.0,<9.0.0"  # Downgraded for graphiti-core compatibility (Sprint 8)
structlog = "^24.4.0"
httpx = "^0.27.0"
aiofiles = "^24.1.0"
pyyaml = "^6.0.0"
python-multipart = "^0.0.20"
numpy = "^1.26.0"  # For vector operations in consolidation
apscheduler = "^3.10.0"  # Cron-based scheduling for memory consolidation (Sprint 9)
psutil = "^5.9.0"  # System resource monitoring (memory/VRAM checks in ingestion - Sprint 32)

# Monitoring (Sprint 2: Metrics)
prometheus-client = "^0.21.0"
slowapi = "^0.1.9"  # Rate limiting

# Database Clients (Sprint 2+: Health Checks, Sprint 5+: Graph DB)
neo4j = "^5.14.0"  # Neo4j driver for health checks (Sprint 5: Graph RAG)
redis = {extras = ["asyncio"], version = "^5.0.0"}  # Redis with async support (Sprint 7: Memory)

# Security & Authentication (Sprint 2: P1 Security)
python-jose = {extras = ["cryptography"], version = "^3.3.0"}  # JWT tokens
passlib = {extras = ["bcrypt"], version = "^1.7.4"}  # Password hashing

# LangGraph & LangChain (Sprint 4: Multi-Agent Orchestration)
langgraph = "^0.6.10"
langchain-core = "^1.0.0"  # Upgraded for langchain-ollama 1.0.0
langchain-ollama = "^1.0.0"  # Latest version, requires ollama>=0.6.0

# LightRAG & Graph (Sprint 5: Graph RAG) - Core only, graspologic moved to optional
lightrag-hku = "^1.4.9"  # LightRAG for knowledge graph construction
networkx = "^3.2"  # Graph algorithms (CORE - needed by LightRAG)
scipy = "^1.11.0"  # Required by networkx.pagerank() in analytics_engine.py

# Graphiti Memory (Sprint 7: Episodic Memory)
graphiti-core = "^0.3.0"  # Episodic memory with temporal graphs
langgraph-checkpoint-redis = "^0.1.2"  # LangGraph Redis checkpointing

# ============================================================================
# OPTIONAL FEATURE GROUPS (Install with: poetry install --with GROUP_NAME)
# ============================================================================

# ----------------------------------------------------------------------------
# INGESTION GROUP: Document ingestion pipeline with LlamaIndex + NLP
# Install: poetry install --with ingestion
# Size: ~500MB (llama-index + spacy models)
# ----------------------------------------------------------------------------
[tool.poetry.group.ingestion]
optional = true

[tool.poetry.group.ingestion.dependencies]
# LlamaIndex Ecosystem (Sprint 2: Document Ingestion, ADR-028 deprecation)
llama-index-core = "^0.14.3"  # Core LlamaIndex (deprecated primary, connectors only)
llama-index-llms-ollama = "^0.8.0"  # LlamaIndex Ollama integration
llama-index-embeddings-ollama = "^0.8.3"  # LlamaIndex embeddings
llama-index-readers-file = "^0.5.4"  # File readers (PDF, DOCX, etc.)
llama-index-vector-stores-qdrant = "^0.8.6"  # Qdrant vector store integration

# NOTE: Docling runs as CONTAINER (HTTP API on port 8080), NOT as Python package
# See: docker-compose.yml (aegis-docling service)
# ADR-039: Section extraction done via Docling Container JSON output, not Python SDK

# Document Format Support
python-pptx = "1.0.2"  # Sprint 16 Feature 16.5: PowerPoint support
docx2txt = "^0.9"  # DOCX text extraction

# NLP & Entity Extraction
spacy = "^3.8.7"  # SpaCy for entity extraction (~200MB with models!)

# ----------------------------------------------------------------------------
# RERANKING GROUP: Cross-encoder reranking for search quality
# Install: poetry install --with reranking
# Size: ~400MB (sentence-transformers + PyTorch models)
# ----------------------------------------------------------------------------
[tool.poetry.group.reranking]
optional = true

[tool.poetry.group.reranking.dependencies]
# Cross-Encoder Reranking (Sprint 3)
sentence-transformers = "^3.3.1"  # HuggingFace cross-encoder models (~300MB + PyTorch)
scikit-learn = "^1.3.0"  # For cosine similarity in semantic deduplication (Sprint 13, ADR-017)

# ----------------------------------------------------------------------------
# EVALUATION GROUP: RAG evaluation with RAGAS
# Install: poetry install --with evaluation
# Size: ~600MB+ (datasets is VERY HEAVY!)
# WARNING: Only install for evaluation tasks, not CI/CD!
# ----------------------------------------------------------------------------
[tool.poetry.group.evaluation]
optional = true

[tool.poetry.group.evaluation.dependencies]
# RAG Evaluation Framework (Sprint 3)
ragas = "^0.3.7"  # RAG evaluation framework (0.3.7 for better Ollama support)
datasets = "^4.0.0"  # HuggingFace datasets for evaluation (~500MB+ !!!)

# ----------------------------------------------------------------------------
# GRAPH-ANALYSIS GROUP: Advanced graph statistics and community detection
# Install: poetry install --with graph-analysis
# Size: ~150MB (NumPy/SciPy heavy dependencies)
# ----------------------------------------------------------------------------
[tool.poetry.group.graph-analysis]
optional = true

[tool.poetry.group.graph-analysis.dependencies]
# Advanced Graph Statistics (Sprint 5)
graspologic = "^3.4.1"  # Graph statistics and community detection (~100MB)

# ----------------------------------------------------------------------------
# UI GROUP: Gradio web interface
# Install: poetry install --with ui
# Size: ~200MB (Gradio + frontend dependencies)
# ----------------------------------------------------------------------------
[tool.poetry.group.ui]
optional = true

[tool.poetry.group.ui.dependencies]
# UI Framework (Sprint 10: Gradio MVP)
gradio = "^5.49.0"  # Gradio for rapid prototyping UI (~150MB + deps)

# ============================================================================
# DEVELOPMENT DEPENDENCIES (Install with: poetry install --with dev)
# ============================================================================
[tool.poetry.group.dev.dependencies]
# Testing
pytest = "^8.0.0"
pytest-asyncio = "^0.23.0"
pytest-cov = "^5.0.0"
pytest-mock = "^3.14.0"
pytest-timeout = "^2.2.0"  # Sprint 13: Prevent hanging tests (TD-29)

# Code Quality
ruff = "^0.14.0"  # Upgraded for Gradio 5.x compatibility
black = "^24.8.0"
mypy = "^1.11.0"
bandit = "^1.7.9"

# Type Stubs
types-pyyaml = "^6.0.0"
types-aiofiles = "^24.1.0"
types-python-jose = "^3.3.4"
types-passlib = "^1.7.7"

# ============================================================================
# BUILD SYSTEM
# ============================================================================
[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

# ============================================================================
# TOOL CONFIGURATIONS
# ============================================================================

[tool.ruff]
line-length = 100
target-version = "py311"
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "N",   # pep8-naming
    "UP",  # pyupgrade
    "B",   # flake8-bugbear
    "C4",   # flake8-comprehensions
    "SIM", # flake8-simplify
]
ignore = [
    "E501",  # line too long (handled by black)
    "B008",  # do not perform function calls in argument defaults
]

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401", "F403"]
"tests/**/*" = ["S101", "PLR2004"]

[tool.ruff.lint.isort]
known-first-party = ["src"]

[tool.black]
line-length = 100
target-version = ["py311"]
include = '\.pyi?$'

[tool.mypy]
# Sprint 25 Feature 25.5: Enable strict mode for type safety
python_version = "3.11"
strict = true

# Strict mode enables these flags:
# - warn_unused_configs
# - disallow_any_generics
# - disallow_subclassing_any
# - disallow_untyped_calls
# - disallow_untyped_defs
# - disallow_incomplete_defs
# - check_untyped_defs
# - disallow_untyped_decorators
# - warn_redundant_casts
# - warn_unused_ignores
# - warn_return_any
# - no_implicit_reexport
# - strict_equality
# - strict_concatenate

# Additional strict checks
warn_return_any = true
warn_unused_configs = true
disallow_any_unimported = true
no_implicit_optional = true
warn_no_return = true
show_error_codes = true
show_column_numbers = true
pretty = true
follow_imports = "normal"

[[tool.mypy.overrides]]
module = [
    "qdrant_client.*",
    "llama_index.*",
    "ollama.*",
    "rank_bm25.*",
    "ragas.*",
    "datasets.*",
    "lightrag.*",
    "networkx.*",
    "graspologic.*",
]
ignore_missing_imports = true

[tool.pytest.ini_options]
minversion = "8.0"
pythonpath = ["src"]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "--verbose",
    "--cov=src",
    "--cov-report=term-missing",
    "--tb=short",
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "sprint8: Sprint 8 critical path E2E tests",
    "slow: Slow tests (>5s execution time)",
]
asyncio_mode = "auto"
