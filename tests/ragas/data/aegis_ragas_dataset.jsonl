{"question": "What is AEGIS RAG?", "ground_truth": "AEGIS RAG (Agentic Enterprise Graph Intelligence System) is a multi-modal RAG system combining vector search (Qdrant), graph reasoning (LightRAG + Neo4j), temporal memory (Graphiti + Redis), and LLM orchestration (LangGraph) for enterprise knowledge retrieval.", "metadata": {"intent": "factual", "domain": "system_architecture", "difficulty": "easy"}}
{"question": "What is the BGE-M3 embedding model?", "ground_truth": "BGE-M3 is a multilingual embedding model that generates 1024-dimensional vectors. It's used in AEGIS RAG for semantic search in Qdrant (ADR-024). BGE-M3 supports 100+ languages and is optimized for retrieval tasks.", "metadata": {"intent": "factual", "domain": "embeddings", "difficulty": "easy"}}
{"question": "What is Qdrant used for in AEGIS RAG?", "ground_truth": "Qdrant is the vector database used for hybrid search combining vector similarity (semantic) with BM25 (keyword) search using Reciprocal Rank Fusion (RRF). It runs on port 6333 (HTTP) and 6334 (gRPC).", "metadata": {"intent": "factual", "domain": "vector_search", "difficulty": "easy"}}
{"question": "What is LangGraph?", "ground_truth": "LangGraph is the orchestration framework used in AEGIS RAG for multi-agent systems. It provides state management, conditional edges, and tools for building agentic workflows. Version 0.6.10 is used.", "metadata": {"intent": "factual", "domain": "orchestration", "difficulty": "easy"}}
{"question": "What is Neo4j used for?", "ground_truth": "Neo4j is the graph database (version 5.24 Community) used for entity and relation extraction in AEGIS RAG. It powers LightRAG's graph-based reasoning and stores knowledge graph triples. Runs on bolt://localhost:7687.", "metadata": {"intent": "factual", "domain": "graph_rag", "difficulty": "easy"}}
{"question": "What is Graphiti?", "ground_truth": "Graphiti is the temporal memory system in AEGIS RAG providing 3-layer memory (episodic, semantic, procedural). It uses Redis for caching and integrates with the Memory Agent for context-aware retrieval.", "metadata": {"intent": "factual", "domain": "memory", "difficulty": "easy"}}
{"question": "What is Docling CUDA?", "ground_truth": "Docling CUDA is the GPU-accelerated document parser (ADR-027) used for ingestion in AEGIS RAG. It handles OCR, table extraction, and layout analysis for PDF/DOCX files using NVIDIA CUDA.", "metadata": {"intent": "factual", "domain": "ingestion", "difficulty": "easy"}}
{"question": "What is AegisLLMProxy?", "ground_truth": "AegisLLMProxy (ADR-033) is the multi-cloud LLM routing layer in AEGIS RAG. It supports Ollama (local), Alibaba Cloud DashScope, and OpenAI with fallback logic and cost tracking. Primary model: Nemotron3 Nano.", "metadata": {"intent": "factual", "domain": "llm_integration", "difficulty": "easy"}}
{"question": "How does hybrid search work in AEGIS RAG?", "ground_truth": "Hybrid search in AEGIS RAG combines vector search (semantic similarity using BGE-M3 embeddings) with BM25 (keyword/lexical matching) and fuses results using Reciprocal Rank Fusion (RRF). This provides best of both: semantic understanding and exact keyword matching. Implemented in FourWayHybridSearch component.", "metadata": {"intent": "exploratory", "domain": "retrieval", "difficulty": "medium"}}
{"question": "Why use Reciprocal Rank Fusion?", "ground_truth": "Reciprocal Rank Fusion (RRF) is used to merge ranked results from multiple retrieval methods (vector + BM25 + graph). RRF formula: score = sum(1/(k+rank_i)) where k=60. It's parameter-free, handles different score scales, and empirically outperforms other fusion methods. RRF gives balanced weight to different retrieval approaches.", "metadata": {"intent": "exploratory", "domain": "retrieval", "difficulty": "medium"}}
{"question": "How does LangGraph orchestrate agents?", "ground_truth": "LangGraph uses a state machine pattern where each agent is a node with conditional edges. The Coordinator Agent routes queries to specialized agents (Vector, Graph, Memory, Action) based on query intent. State is passed through MessageGraph with checkpointing for fault tolerance. Each agent returns results that flow to the next node until the final answer is generated.", "metadata": {"intent": "exploratory", "domain": "orchestration", "difficulty": "medium"}}
{"question": "How does section-aware chunking work?", "ground_truth": "Section-aware chunking (ADR-039) splits documents by semantic sections (headers, paragraphs) instead of fixed token windows. Chunk size: 800-1800 tokens with overlap. Preserves context boundaries, improves retrieval relevance, and maintains semantic coherence. Implemented in the ingestion pipeline with Docling.", "metadata": {"intent": "exploratory", "domain": "ingestion", "difficulty": "medium"}}
{"question": "How does domain training improve retrieval?", "ground_truth": "Domain training in AEGIS RAG allows users to provide example question-answer pairs for specific knowledge domains. The system uses these examples to: (1) Learn domain-specific reranker weights (Feature 69.3), (2) Optimize query rewriting for that domain (Feature 69.4), and (3) Improve context relevance through fine-tuning. Training examples are stored per-domain and used to adjust retrieval parameters.", "metadata": {"intent": "exploratory", "domain": "domain_training", "difficulty": "medium"}}
{"question": "Why use three separate databases?", "ground_truth": "AEGIS RAG uses three databases for different purposes: (1) Qdrant for vector search - optimized for semantic similarity and fast ANN search, (2) Neo4j for graph reasoning - optimized for entity relations and multi-hop queries, (3) Redis for memory caching - optimized for low-latency access to recent context. Each database is purpose-built for its use case, providing better performance than a single general-purpose database.", "metadata": {"intent": "exploratory", "domain": "architecture", "difficulty": "hard"}}
{"question": "Compare LightRAG and Graphiti", "ground_truth": "LightRAG focuses on graph-based retrieval using entity/relation extraction and graph traversal for answering questions (global and local graph modes). Graphiti provides temporal memory management with episodic, semantic, and procedural layers for context-aware responses. LightRAG = static knowledge graph for reasoning, Graphiti = dynamic memory for conversation context. Both use Neo4j and Redis respectively.", "metadata": {"intent": "summary", "domain": "comparison", "difficulty": "medium"}}
{"question": "Summarize the ingestion pipeline", "ground_truth": "AEGIS RAG ingestion pipeline: (1) Docling CUDA parses PDFs/DOCX with OCR, (2) Section-aware chunking creates 800-1800 token chunks, (3) BGE-M3 generates 1024-dim embeddings, (4) Chunks stored in Qdrant with metadata, (5) Entity/relation extraction stores triples in Neo4j, (6) Graphiti updates memory layer. Supports VLM metadata extraction for images. Implemented in document_processing domain.", "metadata": {"intent": "summary", "domain": "ingestion", "difficulty": "medium"}}
{"question": "What are the key ADRs for retrieval?", "ground_truth": "Key retrieval ADRs: ADR-024 (BGE-M3 embeddings for multilingual support), ADR-026 (Pure LLM extraction pipeline for entities), ADR-039 (Section-aware chunking for better context), ADR-040 (RELATES_TO semantic relationships in graph). These ADRs establish the foundation for hybrid retrieval combining vector, keyword, and graph methods.", "metadata": {"intent": "summary", "domain": "adr", "difficulty": "medium"}}
{"question": "Summarize the agent architecture", "ground_truth": "AEGIS RAG uses a multi-agent architecture with LangGraph: Coordinator Agent routes queries by intent (vector/graph/hybrid), Vector Agent handles Qdrant retrieval, Graph Agent performs Neo4j reasoning, Memory Agent accesses Graphiti temporal memory, Action Agent executes tools via MCP. All agents communicate through MessageGraph with shared state. Coordinator uses C-LARA intent classifier (89.5% accuracy) for routing decisions.", "metadata": {"intent": "summary", "domain": "agents", "difficulty": "hard"}}
{"question": "What embedding model does Qdrant use and why?", "ground_truth": "Qdrant uses BGE-M3 (1024-dimensional multilingual embeddings) chosen via ADR-024. Reasons: (1) Multilingual support for 100+ languages, (2) State-of-the-art retrieval performance on MTEB benchmark, (3) Optimized for RAG tasks, (4) Reasonable size (1024-dim balances quality and speed), (5) Open-source and commercially usable. BGE-M3 outperforms alternatives like OpenAI Ada-002 and Cohere embeddings for AEGIS use cases.", "metadata": {"intent": "multi_hop", "domain": "embeddings_retrieval", "difficulty": "hard"}}
{"question": "How does domain training improve reranking and what algorithm is used?", "ground_truth": "Domain training in AEGIS RAG improves reranking through learned weights (Feature 69.3). Process: (1) Users provide training examples (question-answer pairs) for a domain, (2) System evaluates which retrieval method (BM25/vector/graph) performs best for those examples, (3) Learned weights adjust RRF fusion formula to prioritize better-performing methods, (4) Cross-encoder reranker applies domain-specific weights to final ranking. Algorithm: Adaptive RRF with per-domain weight learning using precision@k metric on training examples. Results: +10% precision improvement (Sprint 69).", "metadata": {"intent": "multi_hop", "domain": "domain_training_reranking", "difficulty": "very_hard"}}
