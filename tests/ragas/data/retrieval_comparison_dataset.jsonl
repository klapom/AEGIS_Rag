{"question": "What is the BGE-M3 model version?", "ground_truth": "BGE-M3 is a 1024-dimensional multilingual embedding model. The exact version used in AEGIS RAG is bge-m3:latest from Ollama.", "expected_best_method": "bm25", "metadata": {"intent": "factual", "query_type": "keyword_exact", "difficulty": "easy", "rationale": "Exact keyword match: 'BGE-M3', 'model', 'version' - BM25 excels at exact matches"}}
{"question": "Which port does Qdrant use for HTTP?", "ground_truth": "Qdrant uses port 6333 for HTTP API and port 6334 for gRPC.", "expected_best_method": "bm25", "metadata": {"intent": "factual", "query_type": "keyword_exact", "difficulty": "easy", "rationale": "Specific number query - BM25 better for exact numeric matches like port numbers"}}
{"question": "What is ADR-024 about?", "ground_truth": "ADR-024 documents the decision to use BGE-M3 embeddings (1024-dimensional, multilingual) for vector search in Qdrant.", "expected_best_method": "bm25", "metadata": {"intent": "factual", "query_type": "keyword_exact", "difficulty": "easy", "rationale": "ADR number is exact identifier - BM25 keyword matching ideal"}}
{"question": "How does embedding-based search work?", "ground_truth": "Embedding-based search converts queries and documents into dense vectors (embeddings) in a high-dimensional space. Similar concepts have similar vector representations. Search finds nearest neighbors using distance metrics (cosine similarity, L2). This captures semantic meaning beyond exact keyword matches.", "expected_best_method": "vector", "metadata": {"intent": "exploratory", "query_type": "semantic_concept", "difficulty": "medium", "rationale": "Conceptual understanding needed - vector search excels at semantic similarity"}}
{"question": "Explain the concept of semantic retrieval", "ground_truth": "Semantic retrieval finds documents based on meaning rather than exact keywords. It uses neural embeddings to represent text as vectors where semantically similar content has similar vector representations. Allows finding relevant information even with different wording (e.g., 'car' finds 'automobile').", "expected_best_method": "vector", "metadata": {"intent": "exploratory", "query_type": "semantic_concept", "difficulty": "medium", "rationale": "Pure semantic query - no specific keywords, requires conceptual understanding"}}
{"question": "What are the benefits of neural search?", "ground_truth": "Neural search benefits: (1) Semantic understanding beyond keywords, (2) Multilingual support without translation, (3) Handles synonyms and paraphrasing naturally, (4) Better recall for concept-based queries, (5) Learns from context and domain.", "expected_best_method": "vector", "metadata": {"intent": "exploratory", "query_type": "semantic_concept", "difficulty": "medium", "rationale": "Abstract concept query - vector search captures semantic relationships better"}}
{"question": "Compare keyword and semantic search", "ground_truth": "Keyword search (BM25): Fast, exact matches, works well for specific terms, statistical term weighting. Semantic search (Vector): Understands meaning, handles synonyms, finds conceptually similar content, requires embeddings. Hybrid combines both: exact matches + semantic understanding for best results.", "expected_best_method": "hybrid", "metadata": {"intent": "summary", "query_type": "hybrid_both", "difficulty": "medium", "rationale": "Comparison question benefits from both keyword (terms) and semantic (concepts) understanding"}}
{"question": "What are the benefits of Reciprocal Rank Fusion?", "ground_truth": "Reciprocal Rank Fusion (RRF) benefits: (1) Parameter-free - no weights to tune, (2) Handles different score scales from multiple retrievers, (3) Empirically outperforms linear fusion, (4) Emphasizes top-ranked results, (5) Simple formula: score = sum(1/(k+rank)) where k=60. Used in AEGIS RAG to fuse BM25, vector, and graph results.", "expected_best_method": "hybrid", "metadata": {"intent": "exploratory", "query_type": "hybrid_both", "difficulty": "medium", "rationale": "RRF is hybrid concept - needs both keyword match (term 'RRF') and semantic understanding (benefits)"}}
{"question": "How does AEGIS RAG combine different retrieval methods?", "ground_truth": "AEGIS RAG uses FourWayHybridSearch combining: (1) Vector search (BGE-M3 semantic), (2) BM25 (keyword lexical), (3) Local graph (entity-based), (4) Global graph (community-based). Results fused using Reciprocal Rank Fusion. Then cross-encoder reranking refines top-k. Adaptive weights learned per domain.", "expected_best_method": "hybrid", "metadata": {"intent": "exploratory", "query_type": "hybrid_both", "difficulty": "hard", "rationale": "Complex multi-method query - needs keyword matching (method names) + semantic understanding (how they combine)"}}
{"question": "What is the architecture of AEGIS RAG retrieval system?", "ground_truth": "AEGIS RAG retrieval architecture: FourWayHybridSearch orchestrates multiple retrieval methods (vector, BM25, local/global graph). Qdrant handles vector+BM25 hybrid search. Neo4j provides graph reasoning. Results fused via RRF. Cross-encoder reranker (domain-weighted) refines final ranking. Supports namespace isolation for multi-tenancy.", "expected_best_method": "hybrid", "metadata": {"intent": "summary", "query_type": "hybrid_both", "difficulty": "hard", "rationale": "Architecture query needs both specific component names (keyword) and understanding relationships (semantic)"}}
