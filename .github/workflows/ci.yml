name: CI Pipeline - Unified Quality Gates

on:
  push:
    branches: [main, develop, sprint-*, feature/*]
  pull_request:
    branches: [main, develop]

# Prevent concurrent runs on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.12"
  NODE_VERSION: "20"

jobs:
  # ============================================================
  # JOB 1: CODE QUALITY (Linting, Formatting, Type Checking)
  # ============================================================
  code-quality:
    name: ðŸ” Code Quality
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install --upgrade pip
          pip install poetry
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Code Quality Only)
        run: |
          poetry install --only dev --no-root
      
      - name: Run Ruff Linter
        run: |
          echo "Running Ruff Linter..."
          poetry run ruff check src/ --output-format=github

      - name: Run Black Formatter Check
        run: |
          echo "Checking Black formatting..."
          poetry run black --check --diff src/

      - name: Run MyPy Type Checker (Strict Mode)
        run: |
          echo "Running MyPy type checking in strict mode..."
          poetry run mypy src/ --config-file=pyproject.toml
        # Sprint 25 Feature 25.5: MyPy strict mode enforced (all type errors fixed)

      - name: Run Bandit Security Scanner
        run: |
          echo "Running Bandit security scan..."
          poetry run bandit -r src/ -ll -f json -o bandit-report.json || true
          poetry run bandit -r src/ -ll || true
      
      - name: Upload Bandit Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: bandit-report.json

  # ============================================================
  # JOB 2: PYTHON IMPORT VALIDATION (Sprint 18)
  # ============================================================
  python-import-validation:
    name: ðŸ” Python Import Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install --upgrade pip
          pip install poetry
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core + Ingestion + Reranking for Import Validation)
        run: |
          poetry install --with ingestion,reranking --no-interaction

      - name: Validate All Python Imports
        run: |
          echo "ðŸ” Checking all Python files for import errors..."
          echo "Note: Excluding optional dependency directories (ui, evaluation)"
          failed_files=""

          # Exclude src/ui and src/evaluation (optional dependencies: gradio, ragas)
          for file in $(find src -name "*.py" -type f ! -path "*/ui/*" ! -path "*/evaluation/*"); do
            echo "Checking $file..."
            # Convert file path to module path (keep src. prefix)
            module_path=$(echo $file | sed 's/\//./g' | sed 's/\.py$//')
            if ! poetry run python -c "import sys; sys.path.insert(0, '.'); import $module_path" 2>/dev/null; then
              echo "âŒ Import error in $file"
              poetry run python -c "import sys; sys.path.insert(0, '.'); import $module_path" 2>&1 || true
              failed_files="$failed_files\n$file"
            fi
          done

          if [ -n "$failed_files" ]; then
            echo -e "\nâŒ Import validation failed for:$failed_files"
            exit 1
          fi

          echo "âœ… All imports validated successfully"

      - name: Validate Pydantic Models
        run: |
          echo "ðŸ” Checking Pydantic model imports..."
          poetry run python -c "
          from pathlib import Path
          import re

          errors = []

          for py_file in Path('src').rglob('*.py'):
              content = py_file.read_text()

              # Check if BaseModel is used but not imported
              if 'BaseModel' in content and 'from pydantic' not in content:
                  errors.append(f'{py_file}: Uses BaseModel but missing pydantic import')

          if errors:
              print('\nâŒ Pydantic import errors:')
              print('\n'.join(errors))
              exit(1)

          print('âœ… All Pydantic imports validated')
          "

  # ============================================================
  # JOB 3: NAMING CONVENTIONS CHECK
  # ============================================================
  naming-conventions:
    name: ðŸ“ Naming Conventions
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Check Naming Conventions
        run: |
          echo "Checking naming conventions..."
          # Use find to avoid bash glob expansion issues in CI
          find src -name "*.py" -type f -exec python scripts/check_naming.py {} +

  # ============================================================
  # JOB 4: ADR VALIDATION
  # ============================================================
  adr-validation:
    name: ðŸ“š ADR Validation
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for diff

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Check if ADR needed
        run: |
          echo "Checking if ADR is required..."
          python scripts/check_adr.py
        continue-on-error: true  # Warning only, not blocking

  # ============================================================
  # JOB 5: UNIT TESTS
  # ============================================================
  unit-tests:
    name: ðŸ§ª Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core + Dev)
        run: |
          poetry install --with dev --no-interaction --no-ansi

      - name: Clear Python Bytecode Cache
        run: |
          echo "Clearing Python bytecode cache to prevent stale .pyc issues..."
          find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
          find . -type f -name "*.pyc" -delete 2>/dev/null || true
          echo "Cache cleared"

      - name: Run Unit Tests
        run: |
          echo "Running unit tests..."
          poetry run pytest tests/unit/ tests/components/ tests/api/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --cov-fail-under=50 \
            --junitxml=test-results/unit-results.xml \
            --timeout=300 \
            --timeout-method=thread \
            -v \
            -m "not integration"

      - name: Upload Coverage Report
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-unit
          fail_ci_if_error: true  # Sprint 13: Fail if coverage upload fails

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: |
            test-results/
            coverage.xml
            htmlcov/

  # ============================================================
  # JOB 6: INTEGRATION TESTS (with Docker Services)
  # ============================================================
  integration-tests:
    name: ðŸ”— Integration Tests
    runs-on: ubuntu-latest

    services:
      qdrant:
        image: qdrant/qdrant:v1.11.0
        ports:
          - 6333:6333
        options: >-
          --health-cmd "timeout 1 bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
      
      neo4j:
        image: neo4j:5.24-community
        ports:
          - 7687:7687
          - 7474:7474
        env:
          NEO4J_AUTH: none  # Disable auth for CI tests
          NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
          NEO4J_server_memory_heap_initial__size: 512m
          NEO4J_server_memory_heap_max__size: 1g
        options: >-
          --health-cmd "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"
          --health-interval 10s
          --health-timeout 10s
          --health-retries 20
          --health-start-period 60s
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      # NOTE: Ollama removed - GitHub Actions has no GPU support
      # LLM-dependent tests should be mocked or skipped in CI

    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          # Remove large packages we don't need
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: false  # Keep Docker images for our services
          swap-storage: true

      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core + Dev + Ingestion for Integration)
        run: |
          poetry install --with dev,ingestion --no-interaction --no-ansi

      - name: Wait for Services
        run: |
          echo "ðŸ” Waiting for Qdrant..."
          timeout 90 bash -c 'count=0; until curl -f http://localhost:6333/ 2>/dev/null; do echo "  Qdrant attempt $((++count))..."; sleep 2; done'
          echo "âœ… Qdrant ready"

          echo "ðŸ” Waiting for Neo4j HTTP endpoint..."
          timeout 180 bash -c 'count=0; until curl -f http://localhost:7474/ 2>/dev/null; do echo "  Neo4j HTTP attempt $((++count))/90..."; sleep 2; done'
          echo "âœ… Neo4j HTTP ready"

          echo "ðŸ” Waiting for Neo4j Bolt port (7687) to be ready..."
          echo "  Initial 10s grace period for Neo4j startup..."
          sleep 10
          timeout 120 bash -c 'count=0; until (echo > /dev/tcp/localhost/7687) >/dev/null 2>&1; do echo "  Bolt port check attempt $((++count))/40..."; sleep 3; done'
          echo "âœ… Neo4j Bolt port ready"

          echo "ðŸ” Waiting for Redis..."
          timeout 90 bash -c 'count=0; until redis-cli ping 2>/dev/null; do echo "  Redis attempt $((++count))..."; sleep 2; done'
          echo "âœ… Redis ready"

          echo "ðŸŽ‰ All services ready for integration tests"

      - name: Run Integration Tests
        timeout-minutes: 20  # Increased from default 10 to 20
        env:
          CI: true  # Enable LLM auto-mocking via conftest.py
          QDRANT_HOST: localhost
          QDRANT_PORT: 6333
          NEO4J_URI: bolt://localhost:7687
          NEO4J_USER: ""  # No auth in CI
          NEO4J_PASSWORD: ""  # No auth in CI
          REDIS_HOST: localhost
          REDIS_PORT: 6379
          # NOTE: No Ollama in CI - tests auto-mocked via tests/integration/conftest.py
        run: |
          echo "Running integration tests..."
          poetry run pytest tests/integration/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-append \
            --timeout=300 \
            --timeout-method=thread \
            --junitxml=test-results/integration-results.xml \
            -v
      
      - name: Upload Coverage Report
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: integration
          name: codecov-integration
          fail_ci_if_error: true  # Sprint 13: Fail if coverage upload fails

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            test-results/
            coverage.xml
            htmlcov/

  # ============================================================
  # JOB 7: FRONTEND BUILD & TYPE CHECK (Sprint 18)
  # ============================================================
  frontend-build:
    name: âš›ï¸ Frontend Build & Type Check
    runs-on: ubuntu-latest
    continue-on-error: true  # Optional if frontend doesn't exist

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Check if frontend exists
        id: check_frontend
        run: |
          if [ -d "frontend" ] && [ -f "frontend/package.json" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  Frontend directory not found, skipping frontend jobs"
          fi

      - name: Setup Node.js
        if: steps.check_frontend.outputs.exists == 'true'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: npm ci

      - name: TypeScript Type Check
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: npm run type-check

      - name: Build Frontend
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: npm run build
        env:
          VITE_API_BASE_URL: http://localhost:8000

      - name: Check Bundle Size
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: |
          echo "ðŸ“Š Checking bundle size..."
          BUNDLE_SIZE=$(du -sh dist | cut -f1)
          echo "Bundle size: $BUNDLE_SIZE"

          # Warn if bundle > 2MB
          SIZE_BYTES=$(du -sb dist | cut -f1)
          if [ $SIZE_BYTES -gt 2097152 ]; then
            echo "âš ï¸ Warning: Bundle size exceeds 2MB"
          else
            echo "âœ… Bundle size OK"
          fi

      - name: Upload Build Artifacts
        if: steps.check_frontend.outputs.exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: frontend-dist
          path: frontend/dist

  # ============================================================
  # JOB 8: FRONTEND UNIT TESTS (Sprint 18)
  # ============================================================
  frontend-unit-tests:
    name: âš›ï¸ Frontend Unit Tests
    runs-on: ubuntu-latest
    continue-on-error: true  # Optional if frontend doesn't exist

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        working-directory: frontend
        run: npm ci

      - name: Run Unit Tests
        working-directory: frontend
        run: npm run test:unit
        env:
          CI: true

      - name: Upload Coverage
        uses: codecov/codecov-action@v4
        with:
          file: frontend/coverage/coverage-final.json
          flags: frontend-unit
          name: codecov-frontend-unit

  # ============================================================
  # JOB 9: FRONTEND E2E TESTS (Sprint 18)
  # ============================================================
  frontend-e2e-tests:
    name: ðŸŽ­ Frontend E2E Tests
    runs-on: ubuntu-latest
    continue-on-error: true  # Optional if frontend doesn't exist

    services:
      qdrant:
        image: qdrant/qdrant:v1.11.0
        ports:
          - 6333:6333

      neo4j:
        image: neo4j:5.24-community
        ports:
          - 7687:7687
          - 7474:7474
        env:
          NEO4J_AUTH: none  # Disable auth for CI tests
          NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

      # NOTE: Ollama removed - GitHub Actions has no GPU support
      # Frontend E2E tests should mock backend responses

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install poetry
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Backend Dependencies (Core + Ingestion for E2E)
        run: poetry install --with ingestion --no-interaction

      - name: Wait for Services
        run: |
          timeout 90 bash -c 'until curl -f http://localhost:6333/ 2>/dev/null; do sleep 2; done'
          echo "âœ… Qdrant ready"

          timeout 180 bash -c 'until curl -f http://localhost:7474/ 2>/dev/null; do sleep 2; done'
          echo "âœ… Neo4j ready"

          timeout 90 bash -c 'until redis-cli ping 2>/dev/null; do sleep 2; done'
          echo "âœ… Redis ready"

      - name: Start Backend Server
        run: |
          poetry run uvicorn src.api.main:app --host 0.0.0.0 --port 8000 &
          timeout 60 bash -c 'until curl -f http://localhost:8000/health 2>/dev/null; do sleep 2; done'
          echo "âœ… Backend ready"
        env:
          QDRANT_HOST: localhost
          NEO4J_URI: bolt://localhost:7687
          NEO4J_USER: ""  # No auth in CI
          NEO4J_PASSWORD: ""  # No auth in CI
          REDIS_HOST: localhost

      - name: Install Frontend Dependencies
        working-directory: frontend
        run: npm ci

      - name: Run E2E Tests
        working-directory: frontend
        run: npm test -- --run
        env:
          VITE_API_BASE_URL: http://localhost:8000

      - name: Upload E2E Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results
          path: frontend/test-results/

      - name: Upload E2E Screenshots
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-screenshots
          path: frontend/screenshots/

  # ============================================================
  # JOB 10: API CONTRACT TESTS (Sprint 18)
  # ============================================================
  api-contract-tests:
    name: ðŸ“‹ API Contract Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install poetry
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core for API Contract)
        run: poetry install --no-interaction

      - name: Generate OpenAPI Schema
        run: |
          poetry run python -c "
          from src.api.main import app
          import json

          schema = app.openapi()
          with open('openapi-generated.json', 'w') as f:
              json.dump(schema, f, indent=2)
          "

      - name: Validate OpenAPI Schema
        run: |
          npm install -g @apidevtools/swagger-cli
          swagger-cli validate openapi-generated.json

      - name: Upload OpenAPI Schema
        uses: actions/upload-artifact@v4
        with:
          name: openapi-schema
          path: openapi-generated.json

  # ============================================================
  # JOB 11: SECURITY SCANNING (Dependencies)
  # Note: Consolidated from previous Jobs 11 & 12 (removed redundant dependency-audit)
  # ============================================================
  security-scan:
    name: ðŸ”’ Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Safety
        run: pip install safety
      
      - name: Run Safety Check
        run: |
          echo "Checking dependencies for vulnerabilities..."
          safety check --json --output safety-report.json || true
          safety check
        continue-on-error: true
      
      - name: Upload Safety Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: safety-report
          path: safety-report.json

  # ============================================================
  # JOB 12: DOCKER BUILD TEST
  # ============================================================
  docker-build:
    name: ðŸ³ Docker Build
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't block CI if Docker fails (works locally)

    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: false  # Keep base images for Docker build
          swap-storage: true

      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker Image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.api
          push: false
          load: true
          tags: aegis-rag-api:test
          cache-from: type=gha,scope=aegis-rag  # Add scope for better caching
          cache-to: type=gha,mode=max,scope=aegis-rag
      
      - name: Test Docker Image
        run: |
          docker run --rm aegis-rag-api:test python -c "import src; print('Import successful')"

  # ============================================================
  # JOB 13: DOCUMENTATION CHECK
  # ============================================================
  documentation:
    name: ðŸ“– Documentation
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't block CI for documentation issues

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Check Markdown Links
        run: |
          npm install -g markdown-link-check
          # Find all .md files excluding docs/archive/ and internal guides with anchor links
          find . -name '*.md' \
            -not -path './docs/archive/*' \
            -not -path './docs/CONTEXT_REFRESH_MASTER_GUIDE.md' \
            -not -path './node_modules/*' \
            -not -path './frontend/*' | while read file; do
            echo "Checking $file"
            markdown-link-check "$file" -c .markdown-link-check.json -q || echo "âš ï¸ Warning: Broken links in $file"
          done
      
      - name: Check Docstrings
        run: |
          pip install pydocstyle
          pydocstyle src/ --convention=google --add-ignore=D100,D104,D105,D107
        continue-on-error: true

  # ============================================================
  # JOB 14: UNIFIED QUALITY GATE
  # ============================================================
  quality-gate:
    name: âœ… Unified Quality Gate
    runs-on: ubuntu-latest
    needs:
      - code-quality
      - python-import-validation
      - naming-conventions
      - adr-validation
      - unit-tests
      - integration-tests
      - frontend-build
      - frontend-unit-tests
      - api-contract-tests
      - security-scan
      - docker-build
    if: always()
    
    steps:
      - name: Check Previous Jobs
        run: |
          echo "ðŸ” Checking all quality gates..."

          ALL_PASSED=true

          if [[ "${{ needs.code-quality.result }}" != "success" ]]; then
            echo "âŒ Code Quality failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.python-import-validation.result }}" != "success" ]]; then
            echo "âŒ Python Import Validation failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.naming-conventions.result }}" != "success" ]]; then
            echo "âŒ Naming Conventions failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.adr-validation.result }}" != "success" && "${{ needs.adr-validation.result }}" != "skipped" ]]; then
            echo "âŒ ADR Validation failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.unit-tests.result }}" != "success" ]]; then
            echo "âŒ Unit Tests failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.integration-tests.result }}" != "success" ]]; then
            echo "âŒ Integration Tests failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.frontend-build.result }}" == "failure" ]]; then
            echo "âš ï¸  Frontend Build failed (non-blocking)"
          fi

          if [[ "${{ needs.frontend-unit-tests.result }}" == "failure" ]]; then
            echo "âš ï¸  Frontend Unit Tests failed (non-blocking)"
          fi

          if [[ "${{ needs.api-contract-tests.result }}" != "success" ]]; then
            echo "âŒ API Contract Tests failed"
            ALL_PASSED=false
          fi

          if [[ "${{ needs.security-scan.result }}" != "success" ]]; then
            echo "âš ï¸  Security Scan has warnings (non-blocking)"
          fi

          if [[ "${{ needs.docker-build.result }}" != "success" ]]; then
            echo "âš ï¸  Docker Build failed (non-blocking)"
          fi

          if [ "$ALL_PASSED" = false ]; then
            echo ""
            echo "âŒ QUALITY GATE FAILED"
            exit 1
          fi

          echo ""
          echo "âœ… All critical quality gates passed!"
      
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const summary = `
            ## âœ… Unified Quality Gate Passed

            ### Backend Tests
            - âœ… Code Quality (Ruff + Black + MyPy)
            - âœ… Python Import Validation
            - âœ… Naming Conventions
            - âœ… Unit Tests (>50% coverage)
            - âœ… Integration Tests

            ### Frontend Tests
            - âœ… Frontend Build & Type Check
            - âœ… Frontend Unit Tests
            - âœ… Frontend E2E Tests

            ### API & Security
            - âœ… API Contract Validation
            - âœ… Dependency Audit
            - âœ… Security Scan

            ### Infrastructure
            - âœ… Docker Build

            **Ready for review!** ðŸš€
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

  # ============================================================
  # JOB 15: PERFORMANCE BENCHMARKS (Optional, nur bei Main)
  # ============================================================
  performance:
    name: âš¡ Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (All Features for Performance)
        run: |
          poetry install --all-extras --no-interaction --no-ansi

      - name: Run Benchmarks
        run: |
          echo "Running performance benchmarks..."
          poetry run python tests/performance/benchmark.py
      
      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json
