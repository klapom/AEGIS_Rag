name: CI Pipeline - Unified Quality Gates (Optimized)

on:
  push:
    branches: [main, develop, sprint-*, feature/*]
  pull_request:
    branches: [main, develop]

# Prevent concurrent runs on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.12"
  NODE_VERSION: "20"

# ============================================================
# REUSABLE WORKFLOW: Setup Poetry Cache
# ============================================================
jobs:
  # ============================================================
  # GROUP 1: INSTANT CHECKS (No dependencies, parallel)
  # Estimated time: ~3 minutes (fastest)
  # ============================================================

  code-quality:
    name: ðŸ” Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install --upgrade pip poetry
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Code Quality Only)
        run: |
          poetry install --without monitoring --only dev --no-root

      - name: Run Ruff Linter
        run: poetry run ruff check src/ --output-format=github

      - name: Run Black Formatter Check
        run: poetry run black --check --diff src/

      - name: Run MyPy Type Checker (Strict Mode)
        run: poetry run mypy src/ --config-file=pyproject.toml || true
        # Sprint 25 Feature 25.5: MyPy strict mode (currently non-blocking due to Sprint 20 refactor)

      - name: Run Bandit Security Scanner
        run: |
          poetry run bandit -r src/ -ll -f json -o bandit-report.json || true
          poetry run bandit -r src/ -ll || true

      - name: Upload Bandit Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: bandit-report.json

  naming-conventions:
    name: ðŸ“ Naming Conventions
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Check Naming Conventions
        run: find src -name "*.py" -type f -exec python scripts/check_naming.py {} +

  documentation:
    name: ðŸ“– Documentation
    runs-on: ubuntu-latest
    continue-on-error: true

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Check Markdown Links
        run: |
          npm install -g markdown-link-check
          find . -name '*.md' \
            -not -path './docs/archive/*' \
            -not -path './docs/CONTEXT_REFRESH_MASTER_GUIDE.md' \
            -not -path './node_modules/*' \
            -not -path './frontend/*' | while read file; do
            echo "Checking $file"
            markdown-link-check "$file" -c .markdown-link-check.json -q || echo "âš ï¸ Warning: Broken links in $file"
          done

      - name: Check Docstrings
        run: |
          pip install pydocstyle
          pydocstyle src/ --convention=google --add-ignore=D100,D104,D105,D107
        continue-on-error: true

  # ============================================================
  # GROUP 2: QUICK BUILDS (Frontend & Python validation, ~5 minutes)
  # ============================================================

  python-import-validation:
    name: ðŸ” Python Import Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install --upgrade pip poetry
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core + Dev for Import Validation)
        run: |
          poetry install --without monitoring --with dev --no-interaction --no-ansi

      - name: Verify Critical Dependencies
        run: |
          echo "ðŸ” Verifying Sprint 61 dependencies..."
          poetry run python -c "import sentence_transformers; print('âœ… sentence-transformers')"
          poetry run python -c "import torch; print('âœ… torch')"
          poetry run python -c "from src.domains.vector_search.embedding import NativeEmbeddingService; print('âœ… Native embeddings')"

      - name: Validate All Python Imports
        run: |
          echo "ðŸ” Checking all Python files for import errors..."
          failed_files=""

          for file in $(find src -name "*.py" -type f ! -path "*/ui/*" ! -path "*/evaluation/*"); do
            module_path=$(echo $file | sed 's/\//./g' | sed 's/\.py$//')
            if ! poetry run python -c "import sys; sys.path.insert(0, '.'); import $module_path" 2>/dev/null; then
              failed_files="$failed_files\n$file"
            fi
          done

          if [ -n "$failed_files" ]; then
            echo -e "âŒ Import validation failed for:$failed_files"
            exit 1
          fi

          echo "âœ… All imports validated successfully"

      - name: Validate Pydantic Models
        run: |
          poetry run python -c "
          from pathlib import Path
          errors = []
          for py_file in Path('src').rglob('*.py'):
              content = py_file.read_text()
              if 'BaseModel' in content and 'from pydantic' not in content:
                  errors.append(f'{py_file}: Uses BaseModel but missing pydantic import')
          if errors:
              print('\nâŒ Pydantic import errors:')
              print('\n'.join(errors))
              exit(1)
          print('âœ… All Pydantic imports validated')
          "

  frontend-build:
    name: âš›ï¸ Frontend Build & Type Check
    runs-on: ubuntu-latest
    continue-on-error: true

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Check if frontend exists
        id: check_frontend
        run: |
          if [ -d "frontend" ] && [ -f "frontend/package.json" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  Frontend directory not found"
          fi

      - name: Setup Node.js
        if: steps.check_frontend.outputs.exists == 'true'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: npm ci

      - name: TypeScript Type Check
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: npm run type-check

      - name: Build Frontend
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: npm run build
        env:
          VITE_API_BASE_URL: http://localhost:8000

      - name: Check Bundle Size
        if: steps.check_frontend.outputs.exists == 'true'
        working-directory: frontend
        run: |
          echo "ðŸ“Š Checking bundle size..."
          SIZE_BYTES=$(du -sb dist | cut -f1)
          if [ $SIZE_BYTES -gt 2097152 ]; then
            echo "âš ï¸ Warning: Bundle size exceeds 2MB"
          else
            echo "âœ… Bundle size OK"
          fi

      - name: Upload Build Artifacts
        if: steps.check_frontend.outputs.exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: frontend-dist
          path: frontend/dist

  frontend-unit-tests:
    name: âš›ï¸ Frontend Unit Tests
    runs-on: ubuntu-latest
    continue-on-error: true

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        working-directory: frontend
        run: npm ci

      - name: Run Unit Tests
        working-directory: frontend
        run: npm run test:unit
        env:
          CI: true

      - name: Upload Coverage
        uses: codecov/codecov-action@v4
        with:
          file: frontend/coverage/coverage-final.json
          flags: frontend-unit
          name: codecov-frontend-unit

  # ============================================================
  # GROUP 3: MEDIUM TESTS (Unit + API Contract + Security, ~10 minutes)
  # ============================================================

  unit-tests:
    name: ðŸ§ª Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          swap-storage: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core + Dev)
        run: poetry install --without monitoring --with dev --no-interaction --no-ansi

      - name: Clear Poetry Cache
        run: |
          poetry cache clear pypi --all -n || true
          poetry cache clear PyPI --all -n || true

      - name: Clear Python Bytecode Cache
        run: find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true

      - name: Run Unit Tests (LangSmith Disabled)
        env:
          # Sprint 115: Explicitly disable LangSmith in CI/CD
          # LangSmith traces should ONLY be created during local development/debugging
          # CI/CD runs should never generate external traces to avoid:
          # - Cost overhead (LangSmith API calls)
          # - Noise in trace project (200+ tests create thousands of traces)
          # - Unnecessary dependencies on external services
          LANGSMITH_TRACING: 'false'
          LANGCHAIN_TRACING_V2: 'false'
          LANGSMITH_API_KEY: ''
        run: |
          poetry run pytest tests/unit/ tests/components/ tests/api/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=50 \
            --junitxml=test-results/unit-results.xml \
            --timeout=300 \
            --timeout-method=thread \
            -v \
            -m "not integration and not requires_llm"

      - name: Upload Coverage Report
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-unit
          fail_ci_if_error: true

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: |
            test-results/
            coverage.xml

  api-contract-tests:
    name: ðŸ“‹ API Contract Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          pip install poetry
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core for API Contract)
        run: poetry install --without monitoring --no-interaction

      - name: Generate OpenAPI Schema
        run: |
          poetry run python -c "
          from src.api.main import app
          import json

          schema = app.openapi()
          with open('openapi-generated.json', 'w') as f:
              json.dump(schema, f, indent=2)
          "

      - name: Validate OpenAPI Schema
        run: |
          npm install -g @apidevtools/swagger-cli
          swagger-cli validate openapi-generated.json

      - name: Upload OpenAPI Schema
        uses: actions/upload-artifact@v4
        with:
          name: openapi-schema
          path: openapi-generated.json

  security-scan:
    name: ðŸ”’ Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Safety
        run: pip install safety

      - name: Run Safety Check
        run: |
          safety check --json --output safety-report.json || true
          safety check
        continue-on-error: true

      - name: Upload Safety Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: safety-report
          path: safety-report.json

  # ============================================================
  # GROUP 4: LONG TESTS (Integration Tests)
  # Conditional: Only on PR to main or main branch
  # Estimated time: ~20 minutes
  # ============================================================

  integration-tests:
    name: ðŸ”— Integration Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && github.base_ref == 'main'

    services:
      qdrant:
        image: qdrant/qdrant:v1.11.0
        ports:
          - 6333:6333
        options: >-
          --health-cmd "timeout 1 bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

      neo4j:
        image: neo4j:5.24-community
        ports:
          - 7687:7687
          - 7474:7474
        env:
          NEO4J_AUTH: none
          NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
          NEO4J_server_memory_heap_initial__size: 512m
          NEO4J_server_memory_heap_max__size: 1g
        options: >-
          --health-cmd "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"
          --health-interval 10s
          --health-timeout 10s
          --health-retries 20
          --health-start-period 60s

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: false
          swap-storage: true

      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (Core + Dev + Ingestion for Integration)
        run: poetry install --without monitoring --with dev,ingestion --no-interaction --no-ansi

      - name: Wait for Services
        run: |
          echo "ðŸ” Waiting for Qdrant..."
          timeout 90 bash -c 'count=0; until curl -f http://localhost:6333/ 2>/dev/null; do echo "  Qdrant attempt $((++count))..."; sleep 2; done'
          echo "âœ… Qdrant ready"

          echo "ðŸ” Waiting for Neo4j HTTP endpoint..."
          timeout 180 bash -c 'count=0; until curl -f http://localhost:7474/ 2>/dev/null; do echo "  Neo4j HTTP attempt $((++count))/90..."; sleep 2; done'
          echo "âœ… Neo4j HTTP ready"

          echo "ðŸ” Waiting for Neo4j Bolt port (7687) to be ready..."
          sleep 10
          timeout 120 bash -c 'count=0; until (echo > /dev/tcp/localhost/7687) >/dev/null 2>&1; do echo "  Bolt port check attempt $((++count))/40..."; sleep 3; done'
          echo "âœ… Neo4j Bolt port ready"

          echo "ðŸ” Waiting for Redis port (6379) to be ready..."
          sleep 5
          timeout 60 bash -c 'count=0; until (echo > /dev/tcp/localhost/6379) >/dev/null 2>&1; do echo "  Redis port check attempt $((++count))/30..."; sleep 2; done'
          echo "âœ… Redis port ready"

          echo "ðŸŽ‰ All services ready for integration tests"

      - name: Run Integration Tests (with Auto-Mocking, LangSmith Disabled)
        timeout-minutes: 20
        env:
          CI: true
          QDRANT_HOST: localhost
          QDRANT_PORT: 6333
          NEO4J_URI: bolt://localhost:7687
          NEO4J_USER: ""
          NEO4J_PASSWORD: ""
          REDIS_HOST: localhost
          REDIS_PORT: 6379
          # Sprint 115: Explicitly disable LangSmith in CI/CD integration tests
          LANGSMITH_TRACING: 'false'
          LANGCHAIN_TRACING_V2: 'false'
          LANGSMITH_API_KEY: ''
        run: |
          echo "Running integration tests with auto-mocking..."
          poetry run pytest tests/integration/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-append \
            --timeout=300 \
            --timeout-method=thread \
            --junitxml=test-results/integration-results.xml \
            -v

      - name: Upload Coverage Report
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: integration
          name: codecov-integration
          fail_ci_if_error: true

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            test-results/
            coverage.xml
            htmlcov/

  performance:
    name: âš¡ Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache Poetry Dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true

      - name: Install Dependencies (All Features for Performance)
        run: poetry install --without monitoring --all-extras --no-interaction --no-ansi

      - name: Run Benchmarks
        run: |
          echo "Running performance benchmarks..."
          poetry run python tests/performance/benchmark.py

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json

  # ============================================================
  # QUALITY GATE: Unified Check for ALL Jobs
  # Depends on: All groups (Group 1, 2, 3, 4)
  # ============================================================

  quality-gate:
    name: âœ… Unified Quality Gate
    runs-on: ubuntu-latest
    needs:
      - code-quality
      - naming-conventions
      - documentation
      - python-import-validation
      - frontend-build
      - frontend-unit-tests
      - unit-tests
      - api-contract-tests
      - security-scan
      - integration-tests
      - performance
    if: always()

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Check Previous Jobs (Group 1 - Instant)
        run: |
          echo "========== GROUP 1: INSTANT CHECKS =========="

          if [[ "${{ needs.code-quality.result }}" != "success" ]]; then
            echo "âŒ Code Quality failed"
            exit 1
          fi
          echo "âœ… Code Quality passed"

          if [[ "${{ needs.naming-conventions.result }}" != "success" ]]; then
            echo "âŒ Naming Conventions failed"
            exit 1
          fi
          echo "âœ… Naming Conventions passed"

          if [[ "${{ needs.documentation.result }}" == "failure" ]]; then
            echo "âš ï¸  Documentation check failed (non-blocking)"
          else
            echo "âœ… Documentation check passed"
          fi

      - name: Check Previous Jobs (Group 2 - Quick)
        run: |
          echo ""
          echo "========== GROUP 2: QUICK BUILDS =========="

          if [[ "${{ needs.python-import-validation.result }}" != "success" ]]; then
            echo "âŒ Python Import Validation failed"
            exit 1
          fi
          echo "âœ… Python Import Validation passed"

          if [[ "${{ needs.frontend-build.result }}" == "failure" ]]; then
            echo "âš ï¸  Frontend Build failed (non-blocking)"
          else
            echo "âœ… Frontend Build passed"
          fi

          if [[ "${{ needs.frontend-unit-tests.result }}" == "failure" ]]; then
            echo "âš ï¸  Frontend Unit Tests failed (non-blocking)"
          else
            echo "âœ… Frontend Unit Tests passed"
          fi

      - name: Check Previous Jobs (Group 3 - Medium)
        run: |
          echo ""
          echo "========== GROUP 3: MEDIUM TESTS =========="

          if [[ "${{ needs.unit-tests.result }}" != "success" ]]; then
            echo "âŒ Unit Tests failed"
            exit 1
          fi
          echo "âœ… Unit Tests passed"

          if [[ "${{ needs.api-contract-tests.result }}" != "success" ]]; then
            echo "âŒ API Contract Tests failed"
            exit 1
          fi
          echo "âœ… API Contract Tests passed"

          if [[ "${{ needs.security-scan.result }}" != "success" ]]; then
            echo "âš ï¸  Security Scan has warnings (non-blocking)"
          else
            echo "âœ… Security Scan passed"
          fi

      - name: Check Previous Jobs (Group 4 - Long)
        run: |
          echo ""
          echo "========== GROUP 4: LONG TESTS =========="

          if [[ "${{ needs.integration-tests.result }}" != "success" && "${{ needs.integration-tests.result }}" != "skipped" ]]; then
            echo "âš ï¸  Integration Tests failed/skipped (conditional on PR to main)"
          else
            echo "âœ… Integration Tests passed or skipped (as expected)"
          fi

          if [[ "${{ needs.performance.result }}" != "success" && "${{ needs.performance.result }}" != "skipped" ]]; then
            echo "âš ï¸  Performance Benchmarks failed/skipped (conditional on main branch)"
          else
            echo "âœ… Performance Benchmarks passed or skipped (as expected)"
          fi

      - name: Final Result
        run: |
          echo ""
          echo "=========================================="
          echo "âœ… ALL CRITICAL QUALITY GATES PASSED!"
          echo "=========================================="
          echo ""
          echo "Workflow Summary:"
          echo "- GROUP 1 (Instant):   code-quality, naming-conventions, documentation"
          echo "- GROUP 2 (Quick):     python-import-validation, frontend-build, frontend-unit-tests"
          echo "- GROUP 3 (Medium):    unit-tests, api-contract-tests, security-scan"
          echo "- GROUP 4 (Long):      integration-tests (PR only), performance (main only)"
          echo ""
          echo "Ready for deployment! ðŸš€"

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const summary = `
            ## âœ… Unified Quality Gate Passed (Optimized CI)

            ### GROUP 1: Instant Checks (~3 min)
            - âœ… Code Quality (Ruff + Black + MyPy)
            - âœ… Naming Conventions
            - âœ… Documentation Links

            ### GROUP 2: Quick Builds (~5 min)
            - âœ… Python Import Validation
            - âœ… Frontend Build & Type Check
            - âœ… Frontend Unit Tests

            ### GROUP 3: Medium Tests (~10 min)
            - âœ… Unit Tests (>50% coverage)
            - âœ… API Contract Validation
            - âœ… Security Scan

            ### GROUP 4: Long Tests (~20 min)
            - âœ… Integration Tests (conditional on PR to main)
            - âœ… Performance Benchmarks (conditional on main branch)

            **Job Parallelization:** Sequential groups â†’ Parallel within groups = ~20-25 min total (down from ~45 min)

            **Ready for review!** ðŸš€
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
