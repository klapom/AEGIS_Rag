# ==============================================================================
# AEGIS RAG - Environment Configuration Template
# ==============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!

# ==============================================================================
# Application Settings
# ==============================================================================
APP_NAME=aegis-rag
APP_VERSION=0.1.0
ENVIRONMENT=development  # development, staging, production
DEBUG=false
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
JSON_LOGS=false  # Set to true for production

# ==============================================================================
# API Server Configuration
# ==============================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
API_RELOAD=true  # Auto-reload in development

# ==============================================================================
# LLM Configuration - Ollama (Primary)
# ==============================================================================
# Ollama Server
OLLAMA_BASE_URL=http://localhost:11434

# Ollama Models (pull these first: ollama pull <model>)
OLLAMA_MODEL_GENERATION=llama3.2:8b  # For answer generation
OLLAMA_MODEL_QUERY=llama3.2:3b  # For query understanding
OLLAMA_MODEL_EMBEDDING=nomic-embed-text  # For embeddings

# ==============================================================================
# Azure OpenAI (Optional - Production)
# ==============================================================================
# Set to true to use Azure OpenAI instead of Ollama
USE_AZURE_LLM=false

# Azure OpenAI Credentials (only if USE_AZURE_LLM=true)
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_API_KEY=your-api-key-here
# AZURE_OPENAI_MODEL=gpt-4o
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# ==============================================================================
# Anthropic Claude (Optional - Fallback)
# ==============================================================================
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# ==============================================================================
# Qdrant Vector Database
# ==============================================================================
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_COLLECTION=documents_v1
QDRANT_USE_GRPC=false

# Optional: Qdrant Cloud API Key
# QDRANT_API_KEY=your-qdrant-api-key

# ==============================================================================
# Neo4j Graph Database
# ==============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=aegis-rag-neo4j-password  # CHANGE THIS!
NEO4J_DATABASE=neo4j

# ==============================================================================
# Redis Cache & Short-Term Memory
# ==============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_TTL=3600  # Default TTL in seconds

# Optional: Redis Password
# REDIS_PASSWORD=your-redis-password

# ==============================================================================
# LangSmith Observability (Optional)
# ==============================================================================
LANGSMITH_TRACING=false
# LANGSMITH_API_KEY=your-langsmith-api-key
# LANGSMITH_PROJECT=aegis-rag

# ==============================================================================
# Model Context Protocol (MCP)
# ==============================================================================
MCP_SERVER_PORT=3000
MCP_AUTH_ENABLED=false

# ==============================================================================
# Performance Configuration
# ==============================================================================
MAX_CONCURRENT_REQUESTS=50
REQUEST_TIMEOUT=60  # seconds

# ==============================================================================
# Retrieval Configuration
# ==============================================================================
RETRIEVAL_TOP_K=5
RETRIEVAL_SCORE_THRESHOLD=0.7

# ==============================================================================
# Security (Production)
# ==============================================================================
# JWT_SECRET_KEY=your-secret-key-here-use-long-random-string
# JWT_ALGORITHM=HS256
# JWT_EXPIRATION_MINUTES=60

# ==============================================================================
# CORS (Production)
# ==============================================================================
# ALLOWED_ORIGINS=https://your-frontend.com,https://your-admin.com

# ==============================================================================
# Monitoring (Production)
# ==============================================================================
# SENTRY_DSN=your-sentry-dsn
# PROMETHEUS_ENABLED=true

# ==============================================================================
# Notes
# ==============================================================================
# 1. For local development with Ollama (default):
#    - Ensure Ollama is running: ollama serve
#    - Pull required models:
#      ollama pull llama3.2:3b
#      ollama pull llama3.2:8b
#      ollama pull nomic-embed-text
#
# 2. For production with Azure OpenAI:
#    - Set USE_AZURE_LLM=true
#    - Configure AZURE_OPENAI_* variables
#
# 3. Start services with: docker compose up -d
#    - Qdrant UI: http://localhost:6333/dashboard
#    - Neo4j Browser: http://localhost:7474
#    - Grafana: http://localhost:3000
#    - Prometheus: http://localhost:9090
#
# 4. Security Best Practices:
#    - Change all default passwords!
#    - Use strong random values for secrets
#    - Never commit .env to git
#    - Use secret managers in production (Vault, AWS Secrets Manager)
